{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Following [this](https://pytorch-lightning.readthedocs.io/en/stable/advanced/transfer_learning.html)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Any model that is a PyTorch `nn.Module` can be used with Lightning (because `LightningModules` are `nn.Modules` also).\n",
    "\n",
    "Letâ€™s use the `AutoEncoder` as a feature extractor in a separate model:\n",
    "```python\n",
    "class Encoder(torch.nn.Module):\n",
    "    ...\n",
    "\n",
    "\n",
    "class AutoEncoder(LightningModule):\n",
    "    def __init__(self):\n",
    "        self.encoder = Encoder()\n",
    "        self.decoder = Decoder()\n",
    "\n",
    "\n",
    "class CIFAR10Classifier(LightningModule):\n",
    "    def __init__(self):\n",
    "        # init the pretrained LightningModule\n",
    "        self.feature_extractor = AutoEncoder.load_from_checkpoint(PATH)  # NOTE.\n",
    "        self.feature_extractor.freeze()\n",
    "\n",
    "        # the autoencoder outputs a 100-dim representation and CIFAR-10 has 10 classes\n",
    "        self.classifier = nn.Linear(100, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        representations = self.feature_extractor(x)\n",
    "        x = self.classifier(representations)\n",
    "        ...\n",
    "\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "learn_py38_lightning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3a117739a79adb8d3a3cb28cb225d24b95a2a8e6607bba35806671d6c7dba5eb"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
