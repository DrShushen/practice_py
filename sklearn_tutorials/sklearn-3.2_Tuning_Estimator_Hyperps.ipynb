{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7aa6f784-1900-4b0d-8460-76f609ea2a6b",
   "metadata": {},
   "source": [
    "# Tuning the hyper-parameters of an estimator\n",
    "\n",
    "From this guide: https://scikit-learn.org/stable/modules/grid_search.html"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "771418d9-b4ba-46cd-a612-ce54d0abe4dd",
   "metadata": {},
   "source": [
    "## Overview\n",
    "\n",
    "Hyper-parameters are parameters that are not directly learnt within estimators. \n",
    "\n",
    "üí° In scikit-learn they are **passed as arguments to the constructor of the estimator classes**. Typical examples include `C`, `kernel` and `gamma` for Support Vector Classifier, `alpha` for Lasso, etc.\n",
    "\n",
    "It is possible and recommended to search the hyper-parameter space for the best **cross validation** score.\n",
    "\n",
    "üí° Any parameter provided when constructing an estimator may be optimized in this manner. Specifically, **to find the names and current values for all parameters for a given estimator, use**:\n",
    "```python\n",
    "estimator.get_params()\n",
    "```\n",
    "\n",
    "A search consists of:\n",
    "1. an estimator (regressor or classifier such as `sklearn.svm.SVC()`);\n",
    "2. **a parameter space**;\n",
    "3. a method for searching or sampling candidates;\n",
    "4. a cross-validation scheme; and\n",
    "5. a score function.\n",
    "\n",
    "Two generic approaches to parameter search are provided in scikit-learn: \n",
    "* `GridSearchCV` exhaustively considers all parameter combinations, \n",
    "* `RandomizedSearchCV` can sample a given number of candidates from a parameter space with a specified distribution. \n",
    "\n",
    "Both these tools have successive halving counterparts :\n",
    "* `HalvingGridSearchCV` and \n",
    "* `HalvingRandomSearchCV`, \n",
    "\n",
    "which can be much faster at finding a good parameter combination."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62566cc0-7c7f-4f17-9425-e17bf9efd79a",
   "metadata": {},
   "source": [
    "## [Exhaustive Grid Search](https://scikit-learn.org/stable/modules/grid_search.html#exhaustive-grid-search)\n",
    "\n",
    "`GridSearchCV` exhaustively generates candidates from a grid of parameter values specified with the `param_grid` parameter. For instance, the following param_grid:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "85337a75-ad0e-4651-817c-ff281497f141",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = [\n",
    "  {'C': [1, 10, 100, 1000], 'kernel': ['linear']},\n",
    "  {'C': [1, 10, 100, 1000], 'gamma': [0.001, 0.0001], 'kernel': ['rbf']},\n",
    " ]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aac31b8f-66cb-4401-a267-6d6e7e789d15",
   "metadata": {},
   "source": [
    "specifies that **two grids should be explored**: one with a linear kernel and `C` values in `[1, 10, 100, 1000]`, and the second one with an RBF kernel, and the cross-product of `C` values ranging in `[1, 10, 100, 1000]` and `gamma` values in `[0.001, 0.0001]`.\n",
    "\n",
    "The `GridSearchCV` instance implements the usual estimator API: when ‚Äúfitting‚Äù it on a dataset all the possible combinations of parameter values are evaluated and the best combination is retained."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3267cf9-b25b-409b-b0b2-828d2a7a20c1",
   "metadata": {},
   "source": [
    "### [Example](https://scikit-learn.org/stable/auto_examples/model_selection/plot_grid_search_digits.html#sphx-glr-auto-examples-model-selection-plot-grid-search-digits-py)\n",
    "\n",
    "This examples shows how a **classifier** is optimized by **cross-validation**, which is done using the `GridSearchCV` object on a *development set* that **comprises only half of the available labeled data**.\n",
    "\n",
    "The performance of the selected hyper-parameters and trained model is then measured on a dedicated *evaluation set* that was not used during the model selection step.\n",
    "\n",
    "Note the problem is too easy: the hyperparameter plateau is too flat and the output model is the same for precision and recall with ties in quality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "83c137ef-52b5-43c8-a635-17af0c5b585b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1d9c190f-301d-4327-9cd6-367991c5a755",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the Digits dataset\n",
    "digits = datasets.load_digits()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1e21ee58-9d52-4dbe-a442-2b633f2e0685",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['DESCR', 'data', 'frame', 'images', 'target']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[x for x in dir(digits) if \"_\" not in x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "87511ffb-7960-4696-9cdf-092ad5d3bca5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "digits.images.shape: (1797, 8, 8)\n",
      "digits.target.shape: (1797,)\n"
     ]
    }
   ],
   "source": [
    "print(\"digits.images.shape:\", digits.images.shape)\n",
    "print(\"digits.target.shape:\", digits.target.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8cdf239a-5f36-413d-95fa-9c416c7abcad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X.shape: (1797, 64)\n",
      "y.shape: (1797,)\n"
     ]
    }
   ],
   "source": [
    "# To apply a classifier on this data, we need to flatten the image, to\n",
    "# turn the data in a (samples, feature) matrix:\n",
    "n_samples = len(digits.images)\n",
    "X = digits.images.reshape((n_samples, -1))\n",
    "y = digits.target\n",
    "\n",
    "print(\"X.shape:\", X.shape)\n",
    "print(\"y.shape:\", y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d44766c0-b62f-4b67-aa3f-dee02e798c2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train.shape: (898, 64)\n",
      "y_test.shape: (899,)\n"
     ]
    }
   ],
   "source": [
    "# Split the dataset in two equal parts\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.5, random_state=0)\n",
    "\n",
    "print(\"X_train.shape:\", X_train.shape)\n",
    "print(\"y_test.shape:\", y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c51ddef0-2a87-4b47-802d-bc3ad9f41132",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the parameters by cross-validation\n",
    "tuned_parameters = [\n",
    "    # Grid 1:\n",
    "    {'kernel': ['rbf'], 'gamma': [1e-3, 1e-4], 'C': [1, 10, 100, 1000]},\n",
    "    # Grid 2:\n",
    "    {'kernel': ['linear'], 'C': [1, 10, 100, 1000]}\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6a79b486-9b99-4e8a-a8ee-3a12ed7003a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define scores: \n",
    "scores = ['precision', 'recall']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8ffea0c9-ced6-47a1-aaab-156b34de04db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "# Tuning hyper-parameters for precision\n",
      "\n",
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n",
      "Best parameters set found on development set:\n",
      "\n",
      "{'C': 10, 'gamma': 0.001, 'kernel': 'rbf'}\n",
      "\n",
      "Grid scores on development set:\n",
      "\n",
      "0.986 (+/-0.016) for {'C': 1, 'gamma': 0.001, 'kernel': 'rbf'}\n",
      "0.959 (+/-0.028) for {'C': 1, 'gamma': 0.0001, 'kernel': 'rbf'}\n",
      "0.988 (+/-0.017) for {'C': 10, 'gamma': 0.001, 'kernel': 'rbf'}\n",
      "0.982 (+/-0.026) for {'C': 10, 'gamma': 0.0001, 'kernel': 'rbf'}\n",
      "0.988 (+/-0.017) for {'C': 100, 'gamma': 0.001, 'kernel': 'rbf'}\n",
      "0.983 (+/-0.026) for {'C': 100, 'gamma': 0.0001, 'kernel': 'rbf'}\n",
      "0.988 (+/-0.017) for {'C': 1000, 'gamma': 0.001, 'kernel': 'rbf'}\n",
      "0.983 (+/-0.026) for {'C': 1000, 'gamma': 0.0001, 'kernel': 'rbf'}\n",
      "0.974 (+/-0.012) for {'C': 1, 'kernel': 'linear'}\n",
      "0.974 (+/-0.012) for {'C': 10, 'kernel': 'linear'}\n",
      "0.974 (+/-0.012) for {'C': 100, 'kernel': 'linear'}\n",
      "0.974 (+/-0.012) for {'C': 1000, 'kernel': 'linear'}\n",
      "\n",
      "Detailed classification report:\n",
      "\n",
      "The model is trained on the full development set.\n",
      "The scores are computed on the full evaluation set.\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        89\n",
      "           1       0.97      1.00      0.98        90\n",
      "           2       0.99      0.98      0.98        92\n",
      "           3       1.00      0.99      0.99        93\n",
      "           4       1.00      1.00      1.00        76\n",
      "           5       0.99      0.98      0.99       108\n",
      "           6       0.99      1.00      0.99        89\n",
      "           7       0.99      1.00      0.99        78\n",
      "           8       1.00      0.98      0.99        92\n",
      "           9       0.99      0.99      0.99        92\n",
      "\n",
      "    accuracy                           0.99       899\n",
      "   macro avg       0.99      0.99      0.99       899\n",
      "weighted avg       0.99      0.99      0.99       899\n",
      "\n",
      "\n",
      "================================================================================\n",
      "# Tuning hyper-parameters for recall\n",
      "\n",
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n",
      "Best parameters set found on development set:\n",
      "\n",
      "{'C': 10, 'gamma': 0.001, 'kernel': 'rbf'}\n",
      "\n",
      "Grid scores on development set:\n",
      "\n",
      "0.986 (+/-0.019) for {'C': 1, 'gamma': 0.001, 'kernel': 'rbf'}\n",
      "0.957 (+/-0.028) for {'C': 1, 'gamma': 0.0001, 'kernel': 'rbf'}\n",
      "0.987 (+/-0.019) for {'C': 10, 'gamma': 0.001, 'kernel': 'rbf'}\n",
      "0.981 (+/-0.028) for {'C': 10, 'gamma': 0.0001, 'kernel': 'rbf'}\n",
      "0.987 (+/-0.019) for {'C': 100, 'gamma': 0.001, 'kernel': 'rbf'}\n",
      "0.982 (+/-0.026) for {'C': 100, 'gamma': 0.0001, 'kernel': 'rbf'}\n",
      "0.987 (+/-0.019) for {'C': 1000, 'gamma': 0.001, 'kernel': 'rbf'}\n",
      "0.982 (+/-0.026) for {'C': 1000, 'gamma': 0.0001, 'kernel': 'rbf'}\n",
      "0.971 (+/-0.010) for {'C': 1, 'kernel': 'linear'}\n",
      "0.971 (+/-0.010) for {'C': 10, 'kernel': 'linear'}\n",
      "0.971 (+/-0.010) for {'C': 100, 'kernel': 'linear'}\n",
      "0.971 (+/-0.010) for {'C': 1000, 'kernel': 'linear'}\n",
      "\n",
      "Detailed classification report:\n",
      "\n",
      "The model is trained on the full development set.\n",
      "The scores are computed on the full evaluation set.\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        89\n",
      "           1       0.97      1.00      0.98        90\n",
      "           2       0.99      0.98      0.98        92\n",
      "           3       1.00      0.99      0.99        93\n",
      "           4       1.00      1.00      1.00        76\n",
      "           5       0.99      0.98      0.99       108\n",
      "           6       0.99      1.00      0.99        89\n",
      "           7       0.99      1.00      0.99        78\n",
      "           8       1.00      0.98      0.99        92\n",
      "           9       0.99      0.99      0.99        92\n",
      "\n",
      "    accuracy                           0.99       899\n",
      "   macro avg       0.99      0.99      0.99       899\n",
      "weighted avg       0.99      0.99      0.99       899\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for score in scores:\n",
    "    print(\"=\" * 80)\n",
    "    print(f\"# Tuning hyper-parameters for {score}\")\n",
    "    print()\n",
    "\n",
    "    clf = GridSearchCV(\n",
    "        SVC(), \n",
    "        tuned_parameters,  # <-- The grid.\n",
    "        scoring=f'{score}_macro',\n",
    "        verbose=1\n",
    "    )\n",
    "    clf.fit(X_train, y_train)  # <-- Actually run the grid search.\n",
    "\n",
    "    print(\"Best parameters set found on development set:\")\n",
    "    print()\n",
    "    print(clf.best_params_)\n",
    "    print()\n",
    "    print(\"Grid scores on development set:\")\n",
    "    print()\n",
    "    \n",
    "    # Note the \"mean_test_score\", \"std_test_score\", and \"params\" keys in `cv_results_`:\n",
    "    means = clf.cv_results_['mean_test_score']\n",
    "    stds = clf.cv_results_['std_test_score']\n",
    "    for mean, std, params in zip(means, stds, clf.cv_results_['params']):\n",
    "        print(\"%0.3f (+/-%0.03f) for %r\" % (mean, std * 2, params))\n",
    "    print()\n",
    "\n",
    "    print(\"Detailed classification report:\")\n",
    "    print()\n",
    "    print(\"The model is trained on the full development set.\")\n",
    "    print(\"The scores are computed on the full evaluation set.\")\n",
    "    print()\n",
    "    y_true, y_pred = y_test, clf.predict(X_test)\n",
    "    print(classification_report(y_true, y_pred))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4110b7b-6cc7-442c-a9ec-d79a021e0ee3",
   "metadata": {},
   "source": [
    "### üîë See many good examples in the examples box at the [end of this section](https://scikit-learn.org/stable/modules/grid_search.html#exhaustive-grid-search):\n",
    "\n",
    "* **\\[Done above\\]** See [Parameter estimation using grid search with cross-validation](https://scikit-learn.org/stable/auto_examples/model_selection/plot_grid_search_digits.html#sphx-glr-auto-examples-model-selection-plot-grid-search-digits-py) for an example of Grid Search computation on the digits dataset.\n",
    "\n",
    "* See [Sample pipeline for text feature extraction and evaluation](https://scikit-learn.org/stable/auto_examples/model_selection/grid_search_text_feature_extraction.html#sphx-glr-auto-examples-model-selection-grid-search-text-feature-extraction-py) for an example of Grid Search coupling parameters from a text documents feature extractor (n-gram count vectorizer and TF-IDF transformer) with a classifier (here a linear SVM trained with SGD with either elastic net or L2 penalty) using a `pipeline.Pipeline` instance.\n",
    "\n",
    "* See [Nested versus non-nested cross-validation](https://scikit-learn.org/stable/auto_examples/model_selection/plot_nested_cross_validation_iris.html#sphx-glr-auto-examples-model-selection-plot-nested-cross-validation-iris-py) for an example of Grid Search within a cross validation loop on the iris dataset. **This is the best practice for evaluating the performance of a model with grid search**. *Essentially, this is CV with a validation step -like setup.*\n",
    "\n",
    "* See [Demonstration of **multi-metric evaluation** on cross_val_score and GridSearchCV](https://scikit-learn.org/stable/auto_examples/model_selection/plot_multi_metric_evaluation.html#sphx-glr-auto-examples-model-selection-plot-multi-metric-evaluation-py) for an example of `GridSearchCV` being used to evaluate multiple metrics simultaneously.\n",
    "\n",
    "* See [Balance model complexity and cross-validated score](https://scikit-learn.org/stable/auto_examples/model_selection/plot_grid_search_refit_callable.html#sphx-glr-auto-examples-model-selection-plot-grid-search-refit-callable-py) for an example of using `refit=callable` interface in `GridSearchCV`. The example shows how this interface adds certain amount of flexibility in identifying the ‚Äúbest‚Äù estimator. This interface can also be used in multiple metrics evaluation.\n",
    "\n",
    "* See [Statistical comparison of models using grid search](https://scikit-learn.org/stable/auto_examples/model_selection/plot_grid_search_stats.html#sphx-glr-auto-examples-model-selection-plot-grid-search-stats-py) for an example of how to do a statistical comparison on the outputs of `GridSearchCV`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97c0e4e6-02b1-4bfa-928c-8001726b1f88",
   "metadata": {},
   "source": [
    "## [Randomized Parameter Optimization](https://scikit-learn.org/stable/modules/grid_search.html#randomized-parameter-optimization)\n",
    "\n",
    "While using a grid of parameter settings is currently the most widely used method for parameter optimization, other search methods have more favourable properties. \n",
    "\n",
    "`RandomizedSearchCV` implements a *randomized search over parameters*, where each setting is **sampled from a distribution over possible parameter values**. This has two main benefits over an exhaustive search:\n",
    "* A budget can be chosen independent of the number of parameters and possible values.\n",
    "* Adding parameters that do not influence the performance does not decrease efficiency.\n",
    "\n",
    "Specifying how parameters should be sampled is done *using a dictionary*, very similar to specifying parameters for `GridSearchCV`. Additionally, a computation budget, being the number of sampled candidates or sampling iterations, is specified using the `n_iter` parameter. \n",
    "\n",
    "For each parameter, either a **distribution** over possible values or a **list** of discrete choices (which *will be sampled uniformly*) can be specified:\n",
    "```python\n",
    "{\n",
    "    'C': scipy.stats.expon(scale=100),     # # scipy **distribution**\n",
    "    'gamma': scipy.stats.expon(scale=.1),  # scipy **distribution**\n",
    "    'kernel': ['rbf'],                     # List\n",
    "    'class_weight': ['balanced', None]     # List\n",
    "}\n",
    "```\n",
    "This example uses the `scipy.stats` module, which contains many useful distributions for sampling parameters, such as `expon`, `gamma`, `uniform` or `randint`. In principle, any function can be passed that provides a `rvs` (random variate sample) method to sample a value. A call to the `rvs` function should provide independent random samples from possible parameter values on consecutive calls.\n",
    "\n",
    "‚ö†Ô∏è For *continuous* parameters, such as `C` above, it is important to **specify a continuous distribution** to take full advantage of the randomization. This way, increasing `n_iter` will always lead to a finer search.\n",
    "\n",
    "A continuous log-uniform random variable is available through `loguniform`. *This is a continuous version of log-spaced parameters*. For example to specify `C` above, `loguniform(1, 100)` can be used **instead of** `[1, 10, 100]` or `np.logspace(0, 2, num=1000)`. This is an alias to SciPy‚Äôs `stats.reciprocal`.\n",
    "\n",
    "Mirroring the example above in grid search, we can specify a continuous random variable that is log-uniformly distributed between `1e0` and `1e3`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0baeaf01-a6c8-4a04-ad39-99ad91850a81",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils.fixes import loguniform\n",
    "\n",
    "param_space = {\n",
    "    'C': loguniform(1e0, 1e3),         # `loguniform` continuous, log spaced.\n",
    "    'gamma': loguniform(1e-4, 1e-3),   # `loguniform` continuous, log spaced.\n",
    "    'kernel': ['rbf'],                 # List, discrete.\n",
    "    'class_weight':['balanced', None]  # List, discrete.\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c79acea0-48bc-4266-a6dc-3f2b5a813b27",
   "metadata": {},
   "source": [
    "### [Example: Randomized vs Grid Search](https://scikit-learn.org/stable/auto_examples/model_selection/plot_randomized_search.html#sphx-glr-auto-examples-model-selection-plot-randomized-search-py)\n",
    "\n",
    "Compare randomized search and grid search for optimizing hyperparameters of a *linear SVM* with *SGD training*. All parameters that influence the learning are searched simultaneously (except for the number of estimators, which poses a time / quality tradeoff).\n",
    "\n",
    "**The randomized search and the grid search explore exactly the same space of parameters.** The result in parameter settings is quite similar, while **the run time for randomized search is drastically lower**.\n",
    "\n",
    "The performance may be slightly worse for the randomized search, and is likely due to a noise effect and would not carry over to a held-out test set.\n",
    "\n",
    "Note that in practice, one would not search over this many different parameters simultaneously using grid search, but pick only the ones deemed most important."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9c3c59d5-8740-44aa-b6de-b67b50d91eb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import time\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import scipy.stats as stats\n",
    "from sklearn.utils.fixes import loguniform\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.datasets import load_digits\n",
    "from sklearn.linear_model import SGDClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2e7a3141-e629-45f5-95ff-d0a325ff9e47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1797, 64)\n",
      "(1797,)\n"
     ]
    }
   ],
   "source": [
    "# get some data\n",
    "X, y = load_digits(return_X_y=True)\n",
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7a2cadad-8daf-4041-85b3-5e5d04780cc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SGDClassifier(penalty='elasticnet')\n"
     ]
    }
   ],
   "source": [
    "# build a classifier\n",
    "clf = SGDClassifier(\n",
    "    loss='hinge', \n",
    "    penalty='elasticnet',\n",
    "    fit_intercept=True\n",
    ")\n",
    "print(clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "126b97aa-b02e-402d-a2c7-817161b05dc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utility function to report best scores\n",
    "def report(results, n_top=3):\n",
    "    for i in range(1, n_top + 1):\n",
    "        candidates = np.flatnonzero(results['rank_test_score'] == i)\n",
    "        for candidate in candidates:\n",
    "            print(\"Model with rank: {0}\".format(i))\n",
    "            print(\"Mean validation score: {0:.3f} (std: {1:.3f})\"\n",
    "                  .format(\n",
    "                      results['mean_test_score'][candidate],\n",
    "                      results['std_test_score'][candidate]\n",
    "                  )\n",
    "            )\n",
    "            print(\"Parameters: {0}\".format(results['params'][candidate]))\n",
    "            print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4615e530-ab94-4eb6-b070-3559a8dce8fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# specify parameters and distributions to sample from\n",
    "param_dist = {\n",
    "    'average': [True, False],\n",
    "    'l1_ratio': stats.uniform(0, 1),\n",
    "    'alpha': loguniform(1e-4, 1e0)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "66d6910e-5f02-4c3a-8305-9a9a83c00590",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run randomized search\n",
    "n_iter_search = 20\n",
    "random_search = RandomizedSearchCV(\n",
    "    clf, \n",
    "    param_distributions=param_dist,\n",
    "    n_iter=n_iter_search\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4eb379c8-d32c-4b3b-8e2b-fe15de001261",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomizedSearchCV took 15.52 seconds for 20 candidate parameter settings.\n",
      "Model with rank: 1\n",
      "Mean validation score: 0.928 (std: 0.033)\n",
      "Parameters: {'alpha': 0.8277590142094537, 'average': False, 'l1_ratio': 0.004245259225131637}\n",
      "\n",
      "Model with rank: 2\n",
      "Mean validation score: 0.923 (std: 0.026)\n",
      "Parameters: {'alpha': 0.000808177876312611, 'average': True, 'l1_ratio': 0.20754959699827236}\n",
      "\n",
      "Model with rank: 3\n",
      "Mean validation score: 0.921 (std: 0.032)\n",
      "Parameters: {'alpha': 0.0002004035975261302, 'average': False, 'l1_ratio': 0.9413608653373494}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "start = time()\n",
    "random_search.fit(X, y)\n",
    "print(f\"RandomizedSearchCV took {(time() - start):.2f} seconds for {n_iter_search} candidate parameter settings.\")\n",
    "report(random_search.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "992bec5e-1b03-4c57-9457-db931e45b2ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'average': [True, False],\n",
       " 'l1_ratio': array([0.        , 0.11111111, 0.22222222, 0.33333333, 0.44444444,\n",
       "        0.55555556, 0.66666667, 0.77777778, 0.88888889, 1.        ]),\n",
       " 'alpha': array([1.e-04, 1.e-03, 1.e-02, 1.e-01, 1.e+00])}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# use a full grid over all parameters\n",
    "from IPython.display import display\n",
    "param_grid = {\n",
    "    'average': [True, False],\n",
    "    # Note that here we have to provide a list of discrete values for all!\n",
    "    'l1_ratio': np.linspace(0, 1, num=10),\n",
    "    'alpha': np.power(10, np.arange(-4, 1, dtype=float))\n",
    "}\n",
    "display(param_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "959ffe0f-67e8-47eb-9953-61c95126ae03",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/space/miniconda3/envs/py38_playaround-sk/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:574: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/mnt/space/miniconda3/envs/py38_playaround-sk/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:574: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/mnt/space/miniconda3/envs/py38_playaround-sk/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:574: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/mnt/space/miniconda3/envs/py38_playaround-sk/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:574: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/mnt/space/miniconda3/envs/py38_playaround-sk/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:574: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GridSearchCV took 82.59 seconds for 100 candidate parameter settings.\n",
      "Model with rank: 1\n",
      "Mean validation score: 0.928 (std: 0.033)\n",
      "Parameters: {'alpha': 0.8277590142094537, 'average': False, 'l1_ratio': 0.004245259225131637}\n",
      "\n",
      "Model with rank: 2\n",
      "Mean validation score: 0.923 (std: 0.026)\n",
      "Parameters: {'alpha': 0.000808177876312611, 'average': True, 'l1_ratio': 0.20754959699827236}\n",
      "\n",
      "Model with rank: 3\n",
      "Mean validation score: 0.921 (std: 0.032)\n",
      "Parameters: {'alpha': 0.0002004035975261302, 'average': False, 'l1_ratio': 0.9413608653373494}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# run grid search\n",
    "grid_search = GridSearchCV(clf, param_grid=param_grid)\n",
    "start = time()\n",
    "grid_search.fit(X, y)\n",
    "\n",
    "print(f\"GridSearchCV took {(time() - start):.2f} seconds for {len(grid_search.cv_results_['params'])} candidate parameter settings.\")\n",
    "report(random_search.cv_results_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "374132cb-d1e5-41b6-8f0e-05c6278f5a90",
   "metadata": {},
   "source": [
    "## [Searching for optimal parameters with successive halving](https://scikit-learn.org/stable/modules/grid_search.html#searching-for-optimal-parameters-with-successive-halving)\n",
    "\n",
    "Scikit-learn also provides the \n",
    "* `HalvingGridSearchCV` and \n",
    "* `HalvingRandomSearchCV` \n",
    "\n",
    "estimators that can be used to search a parameter space using successive halving.\n",
    "\n",
    "Successive halving (SH) is like **a tournament among candidate parameter combinations**. \n",
    "1. SH is an iterative selection process where all candidates (the parameter combinations) are evaluated with a small amount of **resources** at the first iteration. \n",
    "2. Only some of these candidates are selected for the next iteration, which will be allocated **more resources**. \n",
    "3. For parameter tuning, the **resource** is typically the *number of training samples*, but it can also be an *arbitrary numeric parameter* such as `n_estimators` in a random forest.\n",
    "\n",
    "As illustrated in the figure below, only a subset of candidates ‚Äòsurvive‚Äô until the last iteration. These are the candidates that have consistently ranked among the top-scoring candidates across all iterations. Each iteration is allocated an *increasing amount of resources per candidate*, here the number of samples:\n",
    "\n",
    "<img src=\"https://scikit-learn.org/stable/_images/sphx_glr_plot_successive_halving_iterations_0012.png\" width=600/>\n",
    "\n",
    "**Parameters:**\n",
    "* The `factor` (> 1) parameter controls the **rate at which the resources grow**, and the **rate at which the number of candidates decreases**. \n",
    "    * In each iteration, the number of resources per candidate is multiplied by `factor` and the number of candidates is divided by the same `factor`. \n",
    "    * Along with `resource` and `min_resources`, `factor` is the most important parameter to control the search in our implementation, though a value of `3` usually works well. \n",
    "    * `factor` **effectively controls the number of iterations** in `HalvingGridSearchCV` and the **number of candidates (by default) and iterations** in `HalvingRandomSearchCV`. \n",
    "* `aggressive_elimination=True` can also be used if the number of available resources is small. \n",
    "* More control is available through tuning the `min_resources` parameter.\n",
    "\n",
    "‚ö†Ô∏è These estimators are still **experimental**: their predictions and their API might change without any deprecation cycle. To use them, you need to explicitly import `enable_halving_search_cv`:\n",
    "```python\n",
    "# explicitly require this experimental feature\n",
    "from sklearn.experimental import enable_halving_search_cv  # noqa\n",
    "# now you can import normally from model_selection\n",
    "from sklearn.model_selection import HalvingGridSearchCV\n",
    "from sklearn.model_selection import HalvingRandomSearchCV\n",
    "```\n",
    "\n",
    "**üìö Detailed discussion of the `Halving` methods:**\n",
    "* [Choosing min_resources and the number of candidates](https://scikit-learn.org/stable/modules/grid_search.html#choosing-min-resources-and-the-number-of-candidates)\n",
    "* [Amount of resource and number of candidates at each iteration](https://scikit-learn.org/stable/modules/grid_search.html#amount-of-resource-and-number-of-candidates-at-each-iteration)\n",
    "* [Choosing a resource](https://scikit-learn.org/stable/modules/grid_search.html#choosing-a-resource)\n",
    "* [Exhausting the available resources](https://scikit-learn.org/stable/modules/grid_search.html#exhausting-the-available-resources)\n",
    "* [Aggressive elimination of candidates](https://scikit-learn.org/stable/modules/grid_search.html#aggressive-elimination-of-candidates)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dab2391-182b-4c8d-8581-211be1ef574b",
   "metadata": {},
   "source": [
    "### [Analysing results with the `cv_results_` attribute](https://scikit-learn.org/stable/modules/grid_search.html#analysing-results-with-the-cv-results-attribute)\n",
    "\n",
    "The `cv_results_` attribute contains useful information for analysing the results of a search. It can be converted to a `pandas` dataframe with `df = pd.DataFrame(est.cv_results_)`. \n",
    "\n",
    "The `cv_results_` attribute of `HalvingGridSearchCV` and `HalvingRandomSearchCV` is similar to that of `GridSearchCV` and `RandomizedSearchCV`, with additional information related to the successive halving process.\n",
    "\n",
    "Here is an example with some of the columns of a (truncated) dataframe:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5e289fa-051a-40f3-a69c-2da3fd2c22fe",
   "metadata": {},
   "source": [
    "<table class=\"docutils align-default\" style=\"margin-left:0; margin-right:auto;\">\n",
    "<colgroup>\n",
    "<col style=\"width: 3%\">\n",
    "<col style=\"width: 5%\">\n",
    "<col style=\"width: 12%\">\n",
    "<col style=\"width: 13%\">\n",
    "<col style=\"width: 67%\">\n",
    "</colgroup>\n",
    "<thead>\n",
    "<tr class=\"row-odd\"><th class=\"head\"></th>\n",
    "<th class=\"head\"><p>iter</p></th>\n",
    "<th class=\"head\"><p>n_resources</p></th>\n",
    "<th class=\"head\"><p>mean_test_score</p></th>\n",
    "<th class=\"head\"><p>params</p></th>\n",
    "</tr>\n",
    "</thead>\n",
    "<tbody>\n",
    "<tr class=\"row-even\"><td><p>0</p></td>\n",
    "<td><p>0</p></td>\n",
    "<td><p>125</p></td>\n",
    "<td><p>0.983667</p></td>\n",
    "<td><p>{‚Äòcriterion‚Äô: ‚Äòentropy‚Äô, ‚Äòmax_depth‚Äô: None, ‚Äòmax_features‚Äô: 9, ‚Äòmin_samples_split‚Äô: 5}</p></td>\n",
    "</tr>\n",
    "<tr class=\"row-odd\"><td><p>1</p></td>\n",
    "<td><p>0</p></td>\n",
    "<td><p>125</p></td>\n",
    "<td><p>0.983667</p></td>\n",
    "<td><p>{‚Äòcriterion‚Äô: ‚Äògini‚Äô, ‚Äòmax_depth‚Äô: None, ‚Äòmax_features‚Äô: 8, ‚Äòmin_samples_split‚Äô: 7}</p></td>\n",
    "</tr>\n",
    "<tr class=\"row-even\"><td><p>2</p></td>\n",
    "<td><p>0</p></td>\n",
    "<td><p>125</p></td>\n",
    "<td><p>0.983667</p></td>\n",
    "<td><p>{‚Äòcriterion‚Äô: ‚Äògini‚Äô, ‚Äòmax_depth‚Äô: None, ‚Äòmax_features‚Äô: 10, ‚Äòmin_samples_split‚Äô: 10}</p></td>\n",
    "</tr>\n",
    "<tr class=\"row-odd\"><td><p>3</p></td>\n",
    "<td><p>0</p></td>\n",
    "<td><p>125</p></td>\n",
    "<td><p>0.983667</p></td>\n",
    "<td><p>{‚Äòcriterion‚Äô: ‚Äòentropy‚Äô, ‚Äòmax_depth‚Äô: None, ‚Äòmax_features‚Äô: 6, ‚Äòmin_samples_split‚Äô: 6}</p></td>\n",
    "</tr>\n",
    "<tr class=\"row-even\"><td><p>‚Ä¶</p></td>\n",
    "<td><p>‚Ä¶</p></td>\n",
    "<td><p>‚Ä¶</p></td>\n",
    "<td><p>‚Ä¶</p></td>\n",
    "<td><p>‚Ä¶</p></td>\n",
    "</tr>\n",
    "<tr class=\"row-odd\"><td><p>15</p></td>\n",
    "<td><p>2</p></td>\n",
    "<td><p>500</p></td>\n",
    "<td><p>0.951958</p></td>\n",
    "<td><p>{‚Äòcriterion‚Äô: ‚Äòentropy‚Äô, ‚Äòmax_depth‚Äô: None, ‚Äòmax_features‚Äô: 9, ‚Äòmin_samples_split‚Äô: 10}</p></td>\n",
    "</tr>\n",
    "<tr class=\"row-even\"><td><p>16</p></td>\n",
    "<td><p>2</p></td>\n",
    "<td><p>500</p></td>\n",
    "<td><p>0.947958</p></td>\n",
    "<td><p>{‚Äòcriterion‚Äô: ‚Äògini‚Äô, ‚Äòmax_depth‚Äô: None, ‚Äòmax_features‚Äô: 10, ‚Äòmin_samples_split‚Äô: 10}</p></td>\n",
    "</tr>\n",
    "<tr class=\"row-odd\"><td><p>17</p></td>\n",
    "<td><p>2</p></td>\n",
    "<td><p>500</p></td>\n",
    "<td><p>0.951958</p></td>\n",
    "<td><p>{‚Äòcriterion‚Äô: ‚Äògini‚Äô, ‚Äòmax_depth‚Äô: None, ‚Äòmax_features‚Äô: 10, ‚Äòmin_samples_split‚Äô: 4}</p></td>\n",
    "</tr>\n",
    "<tr class=\"row-even\"><td><p>18</p></td>\n",
    "<td><p>3</p></td>\n",
    "<td><p>1000</p></td>\n",
    "<td><p>0.961009</p></td>\n",
    "<td><p>{‚Äòcriterion‚Äô: ‚Äòentropy‚Äô, ‚Äòmax_depth‚Äô: None, ‚Äòmax_features‚Äô: 9, ‚Äòmin_samples_split‚Äô: 10}</p></td>\n",
    "</tr>\n",
    "<tr class=\"row-odd\"><td><p>19</p></td>\n",
    "<td><p>3</p></td>\n",
    "<td><p>1000</p></td>\n",
    "<td><p>0.955989</p></td>\n",
    "<td><p>{‚Äòcriterion‚Äô: ‚Äògini‚Äô, ‚Äòmax_depth‚Äô: None, ‚Äòmax_features‚Äô: 10, ‚Äòmin_samples_split‚Äô: 4}</p></td>\n",
    "</tr>\n",
    "</tbody>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "624edfbf-d26f-4780-bafa-1648ca6c6f57",
   "metadata": {},
   "source": [
    "* Each row corresponds to a given parameter combination (a candidate) and a given iteration. \n",
    "* The iteration is given by the `iter` column. \n",
    "* (The `n_resources column` tells you how many resources were used.)\n",
    "\n",
    "In the example above, the best parameter combination is `{'criterion': 'entropy', 'max_depth': None, 'max_features': 9, 'min_samples_split': 10}` since it has reached the last iteration (3) with the highest score: 0.96."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94cc91fc-efb2-4867-b88d-fdbfb47f55a2",
   "metadata": {},
   "source": [
    "## [Tips for parameter search](https://scikit-learn.org/stable/modules/grid_search.html#tips-for-parameter-search\n",
    "\n",
    "\n",
    "\n",
    "#### [Specifying an objective metric:](https://scikit-learn.org/stable/modules/grid_search.html#specifying-an-objective-metric)\n",
    "By **default**, parameter search uses the `score` function of the estimator to evaluate a parameter setting. \n",
    "These are: \n",
    "* `sklearn.metrics.accuracy_score` for **classification** and \n",
    "* `sklearn.metrics.r2_score` for **regression**.\n",
    "\n",
    "An alternative scoring function can be specified **via the `scoring` parameter** of most parameter search tools.\n",
    "\n",
    "\n",
    "\n",
    "#### [Specifying multiple metrics for evaluation](https://scikit-learn.org/stable/modules/grid_search.html#specifying-multiple-metrics-for-evaluation)\n",
    "`GridSearchCV` and `RandomizedSearchCV` allow specifying multiple metrics for the scoring parameter.\n",
    "\n",
    "‚ö†Ô∏è But not the `Halving` searches!\n",
    "\n",
    "Multimetric scoring can either be specified as:\n",
    "* a `list` of strings of predefined scores names \n",
    "* or a `dict` mapping the scorer *name* to the scorer *function* and/or the predefined scorer name(s).\n",
    "\n",
    "‚ö†Ô∏è When specifying multiple metrics, the `refit` parameter **must be set to the metric (string) for which the `best_params_` will be found and used to build the `best_estimator_` on the whole dataset**. If the search should not be refit, set `refit=False`. Leaving refit to the default value `None` will result in an **error** when using multiple metrics. See [example](https://scikit-learn.org/stable/auto_examples/model_selection/plot_multi_metric_evaluation.html#sphx-glr-auto-examples-model-selection-plot-multi-metric-evaluation-py).\n",
    "\n",
    "\n",
    "#### [Composite estimators and parameter spaces](https://scikit-learn.org/stable/auto_examples/model_selection/plot_multi_metric_evaluation.html#sphx-glr-auto-examples-model-selection-plot-multi-metric-evaluation-py)\n",
    "\n",
    "`GridSearchCV` and `RandomizedSearchCV` allow searching over **parameters of *composite* or *nested* estimators** such as:\n",
    "* `Pipeline` [(docs)](https://scikit-learn.org/stable/modules/generated/sklearn.pipeline.Pipeline.html#sklearn.pipeline.Pipeline), \n",
    "* `ColumnTransformer` [(docs)](https://scikit-learn.org/stable/modules/generated/sklearn.compose.ColumnTransformer.html#sklearn.compose.ColumnTransformer), \n",
    "* `VotingClassifier` [(docs)](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.VotingClassifier.html#sklearn.ensemble.VotingClassifier) or \n",
    "* `CalibratedClassifierCV` [(docs)](https://scikit-learn.org/stable/modules/generated/sklearn.calibration.CalibratedClassifierCV.html#sklearn.calibration.CalibratedClassifierCV)\n",
    "\n",
    "using a dedicated `<estimator>__<parameter>` \\[‚ùó\\] syntax:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "fb2a61a3-9a6c-41ca-b8ed-68b6a896dd73",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.calibration import CalibratedClassifierCV  # <-- Composite/nested estimator\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.datasets import make_moons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "60dd7eec-04c9-4f42-a207-8b7521314dbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X.shape: (100, 2)\n",
      "y.shape: (100,)\n",
      "X[0]:\n",
      " [0.1595999  0.98718178]\n",
      "y[0]:\n",
      " 0\n"
     ]
    }
   ],
   "source": [
    "X, y = make_moons()\n",
    "print(\"X.shape:\", X.shape)\n",
    "print(\"y.shape:\", y.shape)\n",
    "print(\"X[0]:\\n\", X[0])\n",
    "print(\"y[0]:\\n\", y[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b507caf4-4555-4e9a-9ec3-158c1f4473ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "calibrated_forest = CalibratedClassifierCV(\n",
    "   base_estimator=RandomForestClassifier(n_estimators=10)\n",
    ")\n",
    "# ^ See this is COMPOSITE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ff969126-0b7c-45ac-9697-496c5c08d6ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n",
      "[CV] END ........................base_estimator__max_depth=2; total time=   0.1s\n",
      "[CV] END ........................base_estimator__max_depth=2; total time=   0.1s\n",
      "[CV] END ........................base_estimator__max_depth=2; total time=   0.1s\n",
      "[CV] END ........................base_estimator__max_depth=2; total time=   0.1s\n",
      "[CV] END ........................base_estimator__max_depth=2; total time=   0.1s\n",
      "[CV] END ........................base_estimator__max_depth=4; total time=   0.1s\n",
      "[CV] END ........................base_estimator__max_depth=4; total time=   0.1s\n",
      "[CV] END ........................base_estimator__max_depth=4; total time=   0.1s\n",
      "[CV] END ........................base_estimator__max_depth=4; total time=   0.1s\n",
      "[CV] END ........................base_estimator__max_depth=4; total time=   0.1s\n",
      "[CV] END ........................base_estimator__max_depth=6; total time=   0.1s\n",
      "[CV] END ........................base_estimator__max_depth=6; total time=   0.1s\n",
      "[CV] END ........................base_estimator__max_depth=6; total time=   0.1s\n",
      "[CV] END ........................base_estimator__max_depth=6; total time=   0.1s\n",
      "[CV] END ........................base_estimator__max_depth=6; total time=   0.1s\n",
      "[CV] END ........................base_estimator__max_depth=8; total time=   0.1s\n",
      "[CV] END ........................base_estimator__max_depth=8; total time=   0.1s\n",
      "[CV] END ........................base_estimator__max_depth=8; total time=   0.1s\n",
      "[CV] END ........................base_estimator__max_depth=8; total time=   0.1s\n",
      "[CV] END ........................base_estimator__max_depth=8; total time=   0.1s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5,\n",
       "             estimator=CalibratedClassifierCV(base_estimator=RandomForestClassifier(n_estimators=10)),\n",
       "             param_grid={'base_estimator__max_depth': [2, 4, 6, 8]}, verbose=2)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Apply GridSearchCV\n",
    "param_grid = {\n",
    "    # ‚ùó <estimator>__<parameter> syntax:\n",
    "    'base_estimator__max_depth': [2, 4, 6, 8]\n",
    "}\n",
    "\n",
    "search = GridSearchCV(\n",
    "    calibrated_forest, \n",
    "    param_grid, \n",
    "    cv=5,\n",
    "    verbose=2,\n",
    ")\n",
    "\n",
    "search.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd6534c4-8ba1-4243-b1b0-3ba0ddb38c5f",
   "metadata": {},
   "source": [
    "Here, `<estimator>` is the parameter name of the nested estimator, in this case `base_estimator`. \n",
    "\n",
    "If the meta-estimator is constructed as a collection of estimators as in `pipeline.Pipeline`, then `<estimator>` refers to the name of the estimator, see [Nested parameters](https://scikit-learn.org/stable/modules/compose.html#pipeline-nested-parameters). \n",
    "\n",
    "In practice, there can be several levels of nesting:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6092edf6-b304-467f-96aa-567c775af179",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n",
      "[CV] END ....model__base_estimator__max_depth=2, select__k=1; total time=   0.1s\n",
      "[CV] END ....model__base_estimator__max_depth=2, select__k=1; total time=   0.1s\n",
      "[CV] END ....model__base_estimator__max_depth=2, select__k=1; total time=   0.1s\n",
      "[CV] END ....model__base_estimator__max_depth=2, select__k=1; total time=   0.1s\n",
      "[CV] END ....model__base_estimator__max_depth=2, select__k=1; total time=   0.1s\n",
      "[CV] END ....model__base_estimator__max_depth=2, select__k=2; total time=   0.1s\n",
      "[CV] END ....model__base_estimator__max_depth=2, select__k=2; total time=   0.1s\n",
      "[CV] END ....model__base_estimator__max_depth=2, select__k=2; total time=   0.1s\n",
      "[CV] END ....model__base_estimator__max_depth=2, select__k=2; total time=   0.1s\n",
      "[CV] END ....model__base_estimator__max_depth=2, select__k=2; total time=   0.1s\n",
      "[CV] END ....model__base_estimator__max_depth=4, select__k=1; total time=   0.1s\n",
      "[CV] END ....model__base_estimator__max_depth=4, select__k=1; total time=   0.1s\n",
      "[CV] END ....model__base_estimator__max_depth=4, select__k=1; total time=   0.1s\n",
      "[CV] END ....model__base_estimator__max_depth=4, select__k=1; total time=   0.1s\n",
      "[CV] END ....model__base_estimator__max_depth=4, select__k=1; total time=   0.1s\n",
      "[CV] END ....model__base_estimator__max_depth=4, select__k=2; total time=   0.1s\n",
      "[CV] END ....model__base_estimator__max_depth=4, select__k=2; total time=   0.1s\n",
      "[CV] END ....model__base_estimator__max_depth=4, select__k=2; total time=   0.1s\n",
      "[CV] END ....model__base_estimator__max_depth=4, select__k=2; total time=   0.1s\n",
      "[CV] END ....model__base_estimator__max_depth=4, select__k=2; total time=   0.1s\n",
      "[CV] END ....model__base_estimator__max_depth=6, select__k=1; total time=   0.1s\n",
      "[CV] END ....model__base_estimator__max_depth=6, select__k=1; total time=   0.1s\n",
      "[CV] END ....model__base_estimator__max_depth=6, select__k=1; total time=   0.1s\n",
      "[CV] END ....model__base_estimator__max_depth=6, select__k=1; total time=   0.1s\n",
      "[CV] END ....model__base_estimator__max_depth=6, select__k=1; total time=   0.1s\n",
      "[CV] END ....model__base_estimator__max_depth=6, select__k=2; total time=   0.1s\n",
      "[CV] END ....model__base_estimator__max_depth=6, select__k=2; total time=   0.1s\n",
      "[CV] END ....model__base_estimator__max_depth=6, select__k=2; total time=   0.1s\n",
      "[CV] END ....model__base_estimator__max_depth=6, select__k=2; total time=   0.1s\n",
      "[CV] END ....model__base_estimator__max_depth=6, select__k=2; total time=   0.1s\n",
      "[CV] END ....model__base_estimator__max_depth=8, select__k=1; total time=   0.1s\n",
      "[CV] END ....model__base_estimator__max_depth=8, select__k=1; total time=   0.1s\n",
      "[CV] END ....model__base_estimator__max_depth=8, select__k=1; total time=   0.1s\n",
      "[CV] END ....model__base_estimator__max_depth=8, select__k=1; total time=   0.1s\n",
      "[CV] END ....model__base_estimator__max_depth=8, select__k=1; total time=   0.1s\n",
      "[CV] END ....model__base_estimator__max_depth=8, select__k=2; total time=   0.1s\n",
      "[CV] END ....model__base_estimator__max_depth=8, select__k=2; total time=   0.1s\n",
      "[CV] END ....model__base_estimator__max_depth=8, select__k=2; total time=   0.1s\n",
      "[CV] END ....model__base_estimator__max_depth=8, select__k=2; total time=   0.1s\n",
      "[CV] END ....model__base_estimator__max_depth=8, select__k=2; total time=   0.1s\n"
     ]
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "\n",
    "pipe = Pipeline(\n",
    "    [\n",
    "        ('select', SelectKBest()),\n",
    "        ('model', calibrated_forest)  # From above example code.\n",
    "    ]\n",
    ")\n",
    "\n",
    "param_grid = {\n",
    "    # <estimator>=`select`, <parameter>=`k`:\n",
    "    'select__k': [1, 2],\n",
    "    # MULTIPLE NESTING <estimator>=`model`, <nested_estimator>=`base_estimator`, <parameter>=`max_depth`\n",
    "    'model__base_estimator__max_depth': [2, 4, 6, 8]\n",
    "}\n",
    "\n",
    "search = GridSearchCV(pipe, param_grid, cv=5, verbose=2).fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dc54eeb-c66c-4ea1-a81c-6c21f4ab162d",
   "metadata": {},
   "source": [
    "#### [Model selection: development and evaluation](https://scikit-learn.org/stable/modules/grid_search.html#model-selection-development-and-evaluation)\n",
    "\n",
    "Model selection by evaluating various parameter settings can be seen as a way to use the labeled data to ‚Äútrain‚Äù the parameters of the grid.\n",
    "\n",
    "When evaluating the resulting model it is important to do it on held-out samples that were not seen during the grid search process: it is recommended to split the data into a **development set** (to be fed to the `GridSearchCV` instance) and an **evaluation set** to compute performance metrics.\n",
    "\n",
    "This can be done by using the `train_test_split` utility function."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c379ee4-e47b-40dc-a4c4-0787e8e81066",
   "metadata": {},
   "source": [
    "#### [Parallelism](https://scikit-learn.org/stable/modules/grid_search.html#parallelism)\n",
    "\n",
    "The parameter search tools evaluate each parameter combination on each data fold independently. \n",
    "\n",
    "Computations *can be run in parallel* by using the keyword `n_jobs=-1`. \n",
    "\n",
    "See function signature for more details, and also the [Glossary entry for `n_jobs`](https://scikit-learn.org/stable/glossary.html#term-n_jobs)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21526422-c79f-4a99-95b6-439fb501fb69",
   "metadata": {},
   "source": [
    "#### [Robustness to failure](https://scikit-learn.org/stable/modules/grid_search.html#robustness-to-failure)\n",
    "\n",
    "Some parameter settings may result in a failure to fit one or more folds of the data. \n",
    "\n",
    "By **default**, this will **cause the entire search to fail**, even if some parameter settings could be fully evaluated. \n",
    "\n",
    "Setting `error_score=0` (or `=np.nan`) **will make the procedure robust to such failure**, issuing a *warning* and setting the score for that fold to `0` (or `NaN`), but completing the search."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba1ad65b-9661-4c2e-ab8d-a988bb28262e",
   "metadata": {},
   "source": [
    "## [Alternatives to brute force parameter search](https://scikit-learn.org/stable/modules/grid_search.html#alternatives-to-brute-force-parameter-search)\n",
    "\n",
    "#### *Model specific* cross-validation\n",
    "\n",
    "> Some models can fit data for a range of values of some parameter almost as efficiently as fitting the estimator for a single value of the parameter.\n",
    "\n",
    "This feature can be leveraged to perform a more efficient cross-validation used for model selection of this parameter.\n",
    "\n",
    "The most common parameter amenable to this strategy is the parameter **encoding the strength of the regularizer**. In this case we say that we compute the **regularization path** of the estimator.\n",
    "\n",
    "Here is the list of such models:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf140ac1-4019-4029-a13c-9ac3c7d7613c",
   "metadata": {},
   "source": [
    "<table class=\"longtable docutils align-default\" style=\"margin-left:0; margin-right:auto;\">\n",
    "<colgroup>\n",
    "<col style=\"width: 10%\">\n",
    "<col style=\"width: 90%\">\n",
    "</colgroup>\n",
    "<tbody>\n",
    "<tr class=\"row-odd\"><td><p><a class=\"reference internal\" href=\"generated/sklearn.linear_model.ElasticNetCV.html#sklearn.linear_model.ElasticNetCV\" title=\"sklearn.linear_model.ElasticNetCV\"><code class=\"xref py py-obj docutils literal notranslate\"><span class=\"pre\">linear_model.ElasticNetCV</span></code></a>(*[,&nbsp;l1_ratio,&nbsp;‚Ä¶])</p></td>\n",
    "<td><p>Elastic Net model with iterative fitting along a regularization path.</p></td>\n",
    "</tr>\n",
    "<tr class=\"row-even\"><td><p><a class=\"reference internal\" href=\"generated/sklearn.linear_model.LarsCV.html#sklearn.linear_model.LarsCV\" title=\"sklearn.linear_model.LarsCV\"><code class=\"xref py py-obj docutils literal notranslate\"><span class=\"pre\">linear_model.LarsCV</span></code></a>(*[,&nbsp;fit_intercept,&nbsp;‚Ä¶])</p></td>\n",
    "<td><p>Cross-validated Least Angle Regression model.</p></td>\n",
    "</tr>\n",
    "<tr class=\"row-odd\"><td><p><a class=\"reference internal\" href=\"generated/sklearn.linear_model.LassoCV.html#sklearn.linear_model.LassoCV\" title=\"sklearn.linear_model.LassoCV\"><code class=\"xref py py-obj docutils literal notranslate\"><span class=\"pre\">linear_model.LassoCV</span></code></a>(*[,&nbsp;eps,&nbsp;n_alphas,&nbsp;‚Ä¶])</p></td>\n",
    "<td><p>Lasso linear model with iterative fitting along a regularization path.</p></td>\n",
    "</tr>\n",
    "<tr class=\"row-even\"><td><p><a class=\"reference internal\" href=\"generated/sklearn.linear_model.LassoLarsCV.html#sklearn.linear_model.LassoLarsCV\" title=\"sklearn.linear_model.LassoLarsCV\"><code class=\"xref py py-obj docutils literal notranslate\"><span class=\"pre\">linear_model.LassoLarsCV</span></code></a>(*[,&nbsp;fit_intercept,&nbsp;‚Ä¶])</p></td>\n",
    "<td><p>Cross-validated Lasso, using the LARS algorithm.</p></td>\n",
    "</tr>\n",
    "<tr class=\"row-odd\"><td><p><a class=\"reference internal\" href=\"generated/sklearn.linear_model.LogisticRegressionCV.html#sklearn.linear_model.LogisticRegressionCV\" title=\"sklearn.linear_model.LogisticRegressionCV\"><code class=\"xref py py-obj docutils literal notranslate\"><span class=\"pre\">linear_model.LogisticRegressionCV</span></code></a>(*[,&nbsp;Cs,&nbsp;‚Ä¶])</p></td>\n",
    "<td><p>Logistic Regression CV (aka logit, MaxEnt) classifier.</p></td>\n",
    "</tr>\n",
    "<tr class=\"row-even\"><td><p><a class=\"reference internal\" href=\"generated/sklearn.linear_model.MultiTaskElasticNetCV.html#sklearn.linear_model.MultiTaskElasticNetCV\" title=\"sklearn.linear_model.MultiTaskElasticNetCV\"><code class=\"xref py py-obj docutils literal notranslate\"><span class=\"pre\">linear_model.MultiTaskElasticNetCV</span></code></a>(*[,&nbsp;‚Ä¶])</p></td>\n",
    "<td><p>Multi-task L1/L2 ElasticNet with built-in cross-validation.</p></td>\n",
    "</tr>\n",
    "<tr class=\"row-odd\"><td><p><a class=\"reference internal\" href=\"generated/sklearn.linear_model.MultiTaskLassoCV.html#sklearn.linear_model.MultiTaskLassoCV\" title=\"sklearn.linear_model.MultiTaskLassoCV\"><code class=\"xref py py-obj docutils literal notranslate\"><span class=\"pre\">linear_model.MultiTaskLassoCV</span></code></a>(*[,&nbsp;eps,&nbsp;‚Ä¶])</p></td>\n",
    "<td><p>Multi-task Lasso model trained with L1/L2 mixed-norm as regularizer.</p></td>\n",
    "</tr>\n",
    "<tr class=\"row-even\"><td><p><a class=\"reference internal\" href=\"generated/sklearn.linear_model.OrthogonalMatchingPursuitCV.html#sklearn.linear_model.OrthogonalMatchingPursuitCV\" title=\"sklearn.linear_model.OrthogonalMatchingPursuitCV\"><code class=\"xref py py-obj docutils literal notranslate\"><span class=\"pre\">linear_model.OrthogonalMatchingPursuitCV</span></code></a>(*)</p></td>\n",
    "<td><p>Cross-validated Orthogonal Matching Pursuit model (OMP).</p></td>\n",
    "</tr>\n",
    "<tr class=\"row-odd\"><td><p><a class=\"reference internal\" href=\"generated/sklearn.linear_model.RidgeCV.html#sklearn.linear_model.RidgeCV\" title=\"sklearn.linear_model.RidgeCV\"><code class=\"xref py py-obj docutils literal notranslate\"><span class=\"pre\">linear_model.RidgeCV</span></code></a>([alphas,&nbsp;‚Ä¶])</p></td>\n",
    "<td><p>Ridge regression with built-in cross-validation.</p></td>\n",
    "</tr>\n",
    "<tr class=\"row-even\"><td><p><a class=\"reference internal\" href=\"generated/sklearn.linear_model.RidgeClassifierCV.html#sklearn.linear_model.RidgeClassifierCV\" title=\"sklearn.linear_model.RidgeClassifierCV\"><code class=\"xref py py-obj docutils literal notranslate\"><span class=\"pre\">linear_model.RidgeClassifierCV</span></code></a>([alphas,&nbsp;‚Ä¶])</p></td>\n",
    "<td><p>Ridge classifier with built-in cross-validation.</p></td>\n",
    "</tr>\n",
    "</tbody>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c8e0ebe-6b4a-47de-8386-2ccfeb2cb070",
   "metadata": {},
   "source": [
    "#### Information Criterion\n",
    "\n",
    "> Some models can offer an **information-theoretic closed-form formula of the optimal estimate of the regularization parameter** by computing a single regularization path (instead of several when using cross-validation).\n",
    "\n",
    "Here is the list of models benefiting from the Akaike Information Criterion (AIC) or the Bayesian Information Criterion (BIC) for automated model selection:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ae63f3b-8f32-4297-b800-b39b34806734",
   "metadata": {},
   "source": [
    "<table class=\"longtable docutils align-default\" style=\"margin-left:0; margin-right:auto;\">\n",
    "<colgroup>\n",
    "<col style=\"width: 10%\">\n",
    "<col style=\"width: 90%\">\n",
    "</colgroup>\n",
    "<tbody>\n",
    "<tr class=\"row-odd\"><td><p><a class=\"reference internal\" href=\"generated/sklearn.linear_model.LassoLarsIC.html#sklearn.linear_model.LassoLarsIC\" title=\"sklearn.linear_model.LassoLarsIC\"><code class=\"xref py py-obj docutils literal notranslate\"><span class=\"pre\">linear_model.LassoLarsIC</span></code></a>([criterion,&nbsp;‚Ä¶])</p></td>\n",
    "<td><p>Lasso model fit with Lars using BIC or AIC for model selection</p></td>\n",
    "</tr>\n",
    "</tbody>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e113f109-7cc0-4781-b80a-dd6ed160dd72",
   "metadata": {},
   "source": [
    "####  Out of Bag Estimates\n",
    "\n",
    "When using *ensemble* methods base upon **bagging**, i.e. generating new training sets using sampling with replacement, part of the training set remains unused. For each classifier in the ensemble, a different part of the training set is left out.\n",
    "\n",
    "*This left out portion can be used to estimate the generalization error without having to rely on a separate validation set*. This estimate comes ‚Äúfor free‚Äù as no additional data is needed and can be used for model selection.\n",
    "\n",
    "This is currently implemented in the following classes:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb03abfb-8891-413e-bb48-37be5014f365",
   "metadata": {},
   "source": [
    "<table class=\"longtable docutils align-default\" style=\"margin-left:0; margin-right:auto;\">\n",
    "<colgroup>\n",
    "<col style=\"width: 10%\">\n",
    "<col style=\"width: 90%\">\n",
    "</colgroup>\n",
    "<tbody>\n",
    "<tr class=\"row-odd\"><td><p><a class=\"reference internal\" href=\"generated/sklearn.ensemble.RandomForestClassifier.html#sklearn.ensemble.RandomForestClassifier\" title=\"sklearn.ensemble.RandomForestClassifier\"><code class=\"xref py py-obj docutils literal notranslate\"><span class=\"pre\">ensemble.RandomForestClassifier</span></code></a>([‚Ä¶])</p></td>\n",
    "<td><p>A random forest classifier.</p></td>\n",
    "</tr>\n",
    "<tr class=\"row-even\"><td><p><a class=\"reference internal\" href=\"generated/sklearn.ensemble.RandomForestRegressor.html#sklearn.ensemble.RandomForestRegressor\" title=\"sklearn.ensemble.RandomForestRegressor\"><code class=\"xref py py-obj docutils literal notranslate\"><span class=\"pre\">ensemble.RandomForestRegressor</span></code></a>([‚Ä¶])</p></td>\n",
    "<td><p>A random forest regressor.</p></td>\n",
    "</tr>\n",
    "<tr class=\"row-odd\"><td><p><a class=\"reference internal\" href=\"generated/sklearn.ensemble.ExtraTreesClassifier.html#sklearn.ensemble.ExtraTreesClassifier\" title=\"sklearn.ensemble.ExtraTreesClassifier\"><code class=\"xref py py-obj docutils literal notranslate\"><span class=\"pre\">ensemble.ExtraTreesClassifier</span></code></a>([‚Ä¶])</p></td>\n",
    "<td><p>An extra-trees classifier.</p></td>\n",
    "</tr>\n",
    "<tr class=\"row-even\"><td><p><a class=\"reference internal\" href=\"generated/sklearn.ensemble.ExtraTreesRegressor.html#sklearn.ensemble.ExtraTreesRegressor\" title=\"sklearn.ensemble.ExtraTreesRegressor\"><code class=\"xref py py-obj docutils literal notranslate\"><span class=\"pre\">ensemble.ExtraTreesRegressor</span></code></a>([n_estimators,&nbsp;‚Ä¶])</p></td>\n",
    "<td><p>An extra-trees regressor.</p></td>\n",
    "</tr>\n",
    "<tr class=\"row-odd\"><td><p><a class=\"reference internal\" href=\"generated/sklearn.ensemble.GradientBoostingClassifier.html#sklearn.ensemble.GradientBoostingClassifier\" title=\"sklearn.ensemble.GradientBoostingClassifier\"><code class=\"xref py py-obj docutils literal notranslate\"><span class=\"pre\">ensemble.GradientBoostingClassifier</span></code></a>(*[,&nbsp;‚Ä¶])</p></td>\n",
    "<td><p>Gradient Boosting for classification.</p></td>\n",
    "</tr>\n",
    "<tr class=\"row-even\"><td><p><a class=\"reference internal\" href=\"generated/sklearn.ensemble.GradientBoostingRegressor.html#sklearn.ensemble.GradientBoostingRegressor\" title=\"sklearn.ensemble.GradientBoostingRegressor\"><code class=\"xref py py-obj docutils literal notranslate\"><span class=\"pre\">ensemble.GradientBoostingRegressor</span></code></a>(*[,&nbsp;‚Ä¶])</p></td>\n",
    "<td><p>Gradient Boosting for regression.</p></td>\n",
    "</tr>\n",
    "</tbody>\n",
    "</table>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
