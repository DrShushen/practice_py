{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial: NLP From Scratch: Translation with a Sequence to Sequence Network and Attention\n",
    "\n",
    "\n",
    "* [Tutorial Link](https://pytorch.org/tutorials/intermediate/seq2seq_translation_tutorial.html)\n",
    "* [Data Link](https://download.pytorch.org/tutorial/data.zip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from io import open\n",
    "import unicodedata\n",
    "import string\n",
    "import re\n",
    "import random\n",
    "from IPython import display as disp\n",
    "import itertools\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "# Device:\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Print / Trace Helpers "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def printt(obj, text, info_only=False):\n",
    "    # Print tensor info.\n",
    "    \n",
    "    global TRACE_ON\n",
    "    \n",
    "    def _p(obj_ii, ii):\n",
    "        print(\">> {} <{}-th>\\nShape: {}\".format(text, ii, obj_ii.shape))\n",
    "        if not info_only:\n",
    "            print(obj_ii)\n",
    "        print()\n",
    "    \n",
    "    if TRACE_ON:\n",
    "        \n",
    "        if isinstance(obj, torch.Tensor):\n",
    "            print(\">> {}\\nShape: {}\".format(text, obj.shape))\n",
    "            if not info_only:\n",
    "                print(obj)\n",
    "        \n",
    "        elif isinstance(obj, (tuple, list)):\n",
    "            for ii, obj_ii in enumerate(obj):\n",
    "                _p(obj_ii, ii)\n",
    "        \n",
    "        print()\n",
    "            \n",
    "\n",
    "def printv(var, text):\n",
    "    # Print variable.\n",
    "    global TRACE_ON\n",
    "    if TRACE_ON:\n",
    "        print(\">> {}:\\n{}\".format(text, var))\n",
    "        print()\n",
    "\n",
    "        \n",
    "def printx(text):\n",
    "    # Just ptint some text.\n",
    "    global TRACE_ON\n",
    "    if TRACE_ON:\n",
    "        print(text)\n",
    "        print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = \"./data/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "SOS_token = 0\n",
    "EOS_token = 1\n",
    "\n",
    "class Lang:\n",
    "    def __init__(self, name):\n",
    "        self.name = name\n",
    "        self.word2index = {}\n",
    "        self.word2count = {}\n",
    "        self.index2word = {0: \"SOS\", 1: \"EOS\"}\n",
    "        self.n_words = 2  # Count SOS and EOS\n",
    "\n",
    "    def addSentence(self, sentence):\n",
    "        for word in sentence.split(' '):\n",
    "            self.addWord(word)\n",
    "\n",
    "    def addWord(self, word):\n",
    "        if word not in self.word2index:\n",
    "            self.word2index[word] = self.n_words\n",
    "            self.word2count[word] = 1\n",
    "            self.index2word[self.n_words] = word\n",
    "            self.n_words += 1\n",
    "        else:\n",
    "            self.word2count[word] += 1\n",
    "    \n",
    "    def __repr__(self):\n",
    "        n_examples = 10\n",
    "        _repr = \"name: {}\\n\".format(self.name)\n",
    "        _repr += \"n_words: {}\\n\".format(self.n_words)\n",
    "        _repr += \"word2count [:5]: {}\\n\".format(tuple(itertools.islice(self.word2count.items(), n_examples)))\n",
    "        _repr += \"word2index [:5]: {}\\n\".format(tuple(itertools.islice(self.word2index.items(), n_examples)))\n",
    "        _repr += \"index2word [:5]: {}\\n\".format(tuple(itertools.islice(self.index2word.items(), n_examples)))\n",
    "        return _repr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Turn a Unicode string to plain ASCII, thanks to\n",
    "# https://stackoverflow.com/a/518232/2809427\n",
    "def unicodeToAscii(s):\n",
    "    return ''.join(\n",
    "        c for c in unicodedata.normalize('NFD', s)\n",
    "        if unicodedata.category(c) != 'Mn'\n",
    "    )\n",
    "\n",
    "# Lowercase, trim, and remove non-letter characters\n",
    "def normalizeString(s):\n",
    "    s = unicodeToAscii(s.lower().strip())\n",
    "    s = re.sub(r\"([.!?])\", r\" \\1\", s)\n",
    "    s = re.sub(r\"[^a-zA-Z.!?]+\", r\" \", s)\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readLangs(lang1, lang2, reverse=False):\n",
    "    print(\"Reading lines...\")\n",
    "\n",
    "    # Read the file and split into lines\n",
    "    lines = open(DATA_PATH + '%s-%s.txt' % (lang1, lang2), encoding='utf-8').\\\n",
    "        read().strip().split('\\n')\n",
    "\n",
    "    # Split every line into pairs and normalize\n",
    "    pairs = [[normalizeString(s) for s in l.split('\\t')] for l in lines]\n",
    "\n",
    "    # Reverse pairs, make Lang instances\n",
    "    if reverse:\n",
    "        pairs = [list(reversed(p)) for p in pairs]\n",
    "        input_lang = Lang(lang2)\n",
    "        output_lang = Lang(lang1)\n",
    "    else:\n",
    "        input_lang = Lang(lang1)\n",
    "        output_lang = Lang(lang2)\n",
    "\n",
    "    return input_lang, output_lang, pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter down to sentences of `MAX_LENGTH` and only those that begin with `eng_prefixes`.\n",
    "\n",
    "MAX_LENGTH = 10\n",
    "\n",
    "eng_prefixes = (\n",
    "    \"i am \", \"i m \",\n",
    "    \"he is\", \"he s \",\n",
    "    \"she is\", \"she s \",\n",
    "    \"you are\", \"you re \",\n",
    "    \"we are\", \"we re \",\n",
    "    \"they are\", \"they re \"\n",
    ")\n",
    "\n",
    "\n",
    "def filterPair(p):\n",
    "    return len(p[0].split(' ')) < MAX_LENGTH and \\\n",
    "        len(p[1].split(' ')) < MAX_LENGTH and \\\n",
    "        p[1].startswith(eng_prefixes)\n",
    "\n",
    "\n",
    "def filterPairs(pairs):\n",
    "    return [pair for pair in pairs if filterPair(pair)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading lines...\n",
      "Read 135842 sentence pairs\n",
      "Trimmed to 10599 sentence pairs\n",
      "Counting words...\n",
      "Counted words:\n",
      "fra 4345\n",
      "eng 2803\n",
      "['tu t exprimes bien .', 'you re articulate .']\n"
     ]
    }
   ],
   "source": [
    "# Data preparation script itself.\n",
    "\n",
    "def prepareData(lang1, lang2, reverse=False):\n",
    "    input_lang, output_lang, pairs = readLangs(lang1, lang2, reverse)\n",
    "    print(\"Read %s sentence pairs\" % len(pairs))\n",
    "    pairs = filterPairs(pairs)\n",
    "    print(\"Trimmed to %s sentence pairs\" % len(pairs))\n",
    "    print(\"Counting words...\")\n",
    "    for pair in pairs:\n",
    "        input_lang.addSentence(pair[0])\n",
    "        output_lang.addSentence(pair[1])\n",
    "    print(\"Counted words:\")\n",
    "    print(input_lang.name, input_lang.n_words)\n",
    "    print(output_lang.name, output_lang.n_words)\n",
    "    return input_lang, output_lang, pairs\n",
    "\n",
    "\n",
    "input_lang, output_lang, pairs = prepareData('eng', 'fra', True)\n",
    "print(random.choice(pairs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['j ai ans .', 'i m .'],\n",
       " ['je vais bien .', 'i m ok .'],\n",
       " ['ca va .', 'i m ok .'],\n",
       " ['je suis gras .', 'i m fat .'],\n",
       " ['je suis gros .', 'i m fat .'],\n",
       " ['je suis en forme .', 'i m fit .'],\n",
       " ['je suis touche !', 'i m hit !'],\n",
       " ['je suis touchee !', 'i m hit !'],\n",
       " ['je suis malade .', 'i m ill .'],\n",
       " ['je suis triste .', 'i m sad .']]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[input_lang]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "name: fra\n",
       "n_words: 4345\n",
       "word2count [:5]: (('j', 414), ('ai', 340), ('ans', 55), ('.', 10262), ('je', 3654), ('vais', 245), ('bien', 104), ('ca', 104), ('va', 51), ('suis', 2544))\n",
       "word2index [:5]: (('j', 2), ('ai', 3), ('ans', 4), ('.', 5), ('je', 6), ('vais', 7), ('bien', 8), ('ca', 9), ('va', 10), ('suis', 11))\n",
       "index2word [:5]: ((0, 'SOS'), (1, 'EOS'), (2, 'j'), (3, 'ai'), (4, 'ans'), (5, '.'), (6, 'je'), (7, 'vais'), (8, 'bien'), (9, 'ca'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[output_lang]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "name: eng\n",
       "n_words: 2803\n",
       "word2count [:5]: (('i', 4305), ('m', 3480), ('.', 10373), ('ok', 10), ('fat', 19), ('fit', 10), ('hit', 4), ('!', 82), ('ill', 7), ('sad', 14))\n",
       "word2index [:5]: (('i', 2), ('m', 3), ('.', 4), ('ok', 5), ('fat', 6), ('fit', 7), ('hit', 8), ('!', 9), ('ill', 10), ('sad', 11))\n",
       "index2word [:5]: ((0, 'SOS'), (1, 'EOS'), (2, 'i'), (3, 'm'), (4, '.'), (5, 'ok'), (6, 'fat'), (7, 'fit'), (8, 'hit'), (9, '!'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Preview the processed data.\n",
    "\n",
    "disp.display(pairs[:10])\n",
    "\n",
    "print(\"\\n[input_lang]\")\n",
    "disp.display(input_lang)\n",
    "\n",
    "print(\"\\n[output_lang]\")\n",
    "disp.display(output_lang)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Seq2Seq Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encoder.\n",
    "\n",
    "class EncoderRNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size):\n",
    "        super(EncoderRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        self.embedding = nn.Embedding(input_size, hidden_size)\n",
    "        self.gru = nn.GRU(hidden_size, hidden_size)\n",
    "\n",
    "    def forward(self, input_, hidden):\n",
    "        embedded = self.embedding(input_).view(1, 1, -1)\n",
    "        output = embedded\n",
    "        output, hidden = self.gru(output, hidden)\n",
    "        return output, hidden\n",
    "\n",
    "    def initHidden(self):\n",
    "        return torch.zeros(1, 1, self.hidden_size, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple decoder.\n",
    "\n",
    "class DecoderRNN(nn.Module):\n",
    "    def __init__(self, hidden_size, output_size):\n",
    "        super(DecoderRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        self.embedding = nn.Embedding(output_size, hidden_size)\n",
    "        self.gru = nn.GRU(hidden_size, hidden_size)\n",
    "        self.out = nn.Linear(hidden_size, output_size)\n",
    "        self.softmax = nn.LogSoftmax(dim=1)\n",
    "\n",
    "    def forward(self, input_, hidden):\n",
    "        output = self.embedding(input_).view(1, 1, -1)\n",
    "        output = F.relu(output)\n",
    "        output, hidden = self.gru(output, hidden)\n",
    "        output = self.softmax(self.out(output[0]))\n",
    "        return output, hidden\n",
    "\n",
    "    def initHidden(self):\n",
    "        return torch.zeros(1, 1, self.hidden_size, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Attention decoder.\n",
    "\n",
    "class AttnDecoderRNN(nn.Module):\n",
    "    def __init__(self, hidden_size, output_size, dropout_p=0.1, max_length=MAX_LENGTH):\n",
    "        super(AttnDecoderRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        self.dropout_p = dropout_p\n",
    "        self.max_length = max_length\n",
    "\n",
    "        self.embedding = nn.Embedding(self.output_size, self.hidden_size)\n",
    "        self.attn = nn.Linear(self.hidden_size * 2, self.max_length)\n",
    "        self.attn_combine = nn.Linear(self.hidden_size * 2, self.hidden_size)\n",
    "        self.dropout = nn.Dropout(self.dropout_p)\n",
    "        self.gru = nn.GRU(self.hidden_size, self.hidden_size)\n",
    "        self.out = nn.Linear(self.hidden_size, self.output_size)\n",
    "\n",
    "    def forward(self, input_, hidden, encoder_outputs):\n",
    "        embedded = self.embedding(input_).view(1, 1, -1)\n",
    "        embedded = self.dropout(embedded)\n",
    "\n",
    "        attn_weights = F.softmax(\n",
    "            self.attn(torch.cat((embedded[0], hidden[0]), 1)), dim=1)\n",
    "        attn_applied = torch.bmm(attn_weights.unsqueeze(0),\n",
    "                                 encoder_outputs.unsqueeze(0))\n",
    "\n",
    "        output = torch.cat((embedded[0], attn_applied[0]), 1)\n",
    "        output = self.attn_combine(output).unsqueeze(0)\n",
    "\n",
    "        output = F.relu(output)\n",
    "        output, hidden = self.gru(output, hidden)\n",
    "\n",
    "        output = F.log_softmax(self.out(output[0]), dim=1)\n",
    "        return output, hidden, attn_weights\n",
    "\n",
    "    def initHidden(self):\n",
    "        return torch.zeros(1, 1, self.hidden_size, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def indexesFromSentence(lang, sentence):\n",
    "    return [lang.word2index[word] for word in sentence.split(' ')]\n",
    "\n",
    "\n",
    "def tensorFromSentence(lang, sentence):\n",
    "    indexes = indexesFromSentence(lang, sentence)\n",
    "    indexes.append(EOS_token)\n",
    "    return torch.tensor(indexes, dtype=torch.long, device=device).view(-1, 1)\n",
    "\n",
    "\n",
    "def tensorsFromPair(pair):\n",
    "    input_tensor = tensorFromSentence(input_lang, pair[0])\n",
    "    target_tensor = tensorFromSentence(output_lang, pair[1])\n",
    "    return (input_tensor, target_tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training function: ONE ITERATION.\n",
    "\n",
    "teacher_forcing_ratio = 0.5\n",
    "\n",
    "\n",
    "def train(input_tensor, target_tensor, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion, max_length=MAX_LENGTH, debug_mode=False):\n",
    "    encoder_hidden = encoder.initHidden()\n",
    "\n",
    "    encoder_optimizer.zero_grad()\n",
    "    decoder_optimizer.zero_grad()\n",
    "\n",
    "    input_length = input_tensor.size(0)\n",
    "    target_length = target_tensor.size(0)\n",
    "\n",
    "    encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\n",
    "    printt(encoder_outputs, \"encoder_outputs\")\n",
    "    \n",
    "    loss = 0\n",
    "    \n",
    "    printx(\"ENCODER LOOP ... ... ... ... ... ... ... ...\\nfor ei in range(input_length):\")\n",
    "    for ei in range(input_length):\n",
    "        printv(ei, \"ei\")\n",
    "        encoder_output, encoder_hidden = encoder(input_tensor[ei], encoder_hidden)\n",
    "        printt(encoder_hidden, \"encoder_hidden\", info_only=True)\n",
    "        # TODO: print --> encoder_output\n",
    "        encoder_outputs[ei] = encoder_output[0, 0]\n",
    "    printx(\"... ... ... ... ... ... ... ... ... ...\")\n",
    "\n",
    "    decoder_input = torch.tensor([[SOS_token]], device=device)\n",
    "    printt(decoder_input, \"decoder_input\")\n",
    "    \n",
    "    decoder_hidden = encoder_hidden\n",
    "    printx(\"decoder_hidden = encoder_hidden\")\n",
    "    printt(decoder_hidden, \"decoder_hidden\", info_only=True)\n",
    "\n",
    "    use_teacher_forcing = True if random.random() < teacher_forcing_ratio else False\n",
    "    \n",
    "    if debug_mode:\n",
    "        use_teacher_forcing = False\n",
    "    printv(use_teacher_forcing, \"use_teacher_forcing\")\n",
    "    \n",
    "    printx(\"DECODER LOOP ... ... ... ... ... ... ... ...\\nfor di in range(target_length):\")\n",
    "    \n",
    "    if use_teacher_forcing:\n",
    "        # Teacher forcing: Feed the target as the next input\n",
    "        \n",
    "        for di in range(target_length):\n",
    "            printv(di, \"di\")\n",
    "            \n",
    "            if isinstance(decoder, AttnDecoderRNN):\n",
    "                decoder_output, decoder_hidden, decoder_attention = decoder(decoder_input, decoder_hidden, encoder_outputs)\n",
    "            else:\n",
    "                decoder_output, decoder_hidden = decoder(decoder_input, decoder_hidden)\n",
    "                printt(decoder_output, \"decoder_output\", info_only=True)\n",
    "                printt(decoder_hidden, \"decoder_hidden\", info_only=True)\n",
    "            \n",
    "            target = target_tensor[di]\n",
    "            printt(target, \"target\")\n",
    "            \n",
    "            loss += criterion(decoder_output, target)\n",
    "            printv(loss.item(), \"loss += criterion(decoder_output, target)\")\n",
    "            \n",
    "            decoder_input = target_tensor[di]  # Teacher forcing\n",
    "            printx(\"decoder_input = target_tensor[di]\")\n",
    "            printt(decoder_input, \"decoder_input\")\n",
    "\n",
    "    else:\n",
    "        # Without teacher forcing: use its own predictions as the next input\n",
    "        for di in range(target_length):\n",
    "            printv(di, \"di\")\n",
    "            \n",
    "            if isinstance(decoder, AttnDecoderRNN):\n",
    "                decoder_output, decoder_hidden, decoder_attention = decoder(decoder_input, decoder_hidden, encoder_outputs)\n",
    "            else:\n",
    "                decoder_output, decoder_hidden = decoder(decoder_input, decoder_hidden)\n",
    "                printt(decoder_output, \"decoder_output\", info_only=True)\n",
    "                printt(decoder_hidden, \"decoder_hidden\", info_only=True)\n",
    "            \n",
    "            topv, topi = decoder_output.topk(1)\n",
    "            printx(\"topv, topi = decoder_output.topk(1)\")\n",
    "            printv(topv, \"topv\")\n",
    "            printv(topi, \"topi\")\n",
    "            \n",
    "            decoder_input = topi.squeeze().detach()  # detach from history as input\n",
    "            printx(\"decoder_input = topi.squeeze().detach()\")\n",
    "            printt(decoder_input, \"decoder_input\")\n",
    "\n",
    "            target = target_tensor[di]\n",
    "            printt(target, \"target\")\n",
    "            \n",
    "            loss += criterion(decoder_output, target)\n",
    "            printv(loss.item(), \"loss += criterion(decoder_output, target)\")\n",
    "            \n",
    "            if decoder_input.item() == EOS_token:\n",
    "                break\n",
    "    \n",
    "    printx(\"... ... ... ... ... ... ... ... ... ...\")\n",
    "    \n",
    "    loss.backward()\n",
    "\n",
    "    encoder_optimizer.step()\n",
    "    decoder_optimizer.step()\n",
    "\n",
    "    return loss.item() / target_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Timer helpers.\n",
    "\n",
    "import time\n",
    "import math\n",
    "\n",
    "\n",
    "def asMinutes(s):\n",
    "    m = math.floor(s / 60)\n",
    "    s -= m * 60\n",
    "    return '%dm %ds' % (m, s)\n",
    "\n",
    "\n",
    "def timeSince(since, percent):\n",
    "    now = time.time()\n",
    "    s = now - since\n",
    "    es = s / (percent)\n",
    "    rs = es - s\n",
    "    return '%s (- %s)' % (asMinutes(s), asMinutes(rs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The whole training process looks like this:\n",
    "* Start a timer\n",
    "* Initialize optimizers and criterion\n",
    "* Create set of training pairs\n",
    "* Start empty losses array for plotting\n",
    "\n",
    "Then we call `train` many times and occasionally print the progress (% of examples, time so far, estimated time) and average loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainIters(encoder, decoder, n_iters, print_every=1000, plot_every=100, learning_rate=0.01, debug_mode=False):\n",
    "    \n",
    "    start = time.time()\n",
    "    plot_losses = []\n",
    "    print_loss_total = 0  # Reset every print_every\n",
    "    plot_loss_total = 0  # Reset every plot_every\n",
    "\n",
    "    encoder_optimizer = optim.SGD(encoder.parameters(), lr=learning_rate)\n",
    "    decoder_optimizer = optim.SGD(decoder.parameters(), lr=learning_rate)\n",
    "    \n",
    "    picked_pairs = [random.choice(pairs) for i in range(n_iters)]\n",
    "    training_pairs = [tensorsFromPair(p) for p in picked_pairs]\n",
    "    \n",
    "    printx(\"Example sentence data: ---\")\n",
    "    printv(picked_pairs[0], \"picked_pairs[0]\")\n",
    "    printt(training_pairs[0], \"training_pairs[0]\")\n",
    "    printx(\"--- --- --- --- --- --- ---\")\n",
    "    \n",
    "    criterion = nn.NLLLoss()\n",
    "    \n",
    "    # If in debug mode, only one iteration will be run.\n",
    "    if debug_mode:\n",
    "        n_iters = 1\n",
    "    \n",
    "    for iter in range(1, n_iters + 1):\n",
    "        \n",
    "        printv(iter, \"iter\")\n",
    "        \n",
    "        training_pair = training_pairs[iter - 1]\n",
    "        printt(training_pair, \"training_pair\")\n",
    "        \n",
    "        input_tensor = training_pair[0]\n",
    "        target_tensor = training_pair[1]\n",
    "\n",
    "        loss = train(input_tensor, target_tensor, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion, debug_mode=debug_mode)\n",
    "        print_loss_total += loss\n",
    "        plot_loss_total += loss\n",
    "\n",
    "        if iter % print_every == 0 or debug_mode:\n",
    "            print_loss_avg = print_loss_total / print_every\n",
    "            printv(print_loss_avg, \"print_loss_avg\")\n",
    "            \n",
    "            print_loss_total = 0\n",
    "            print('%s (%d %d%%) %.4f' % (timeSince(start, iter / n_iters), iter, iter / n_iters * 100, print_loss_avg))\n",
    "\n",
    "        if iter % plot_every == 0:\n",
    "            plot_loss_avg = plot_loss_total / plot_every\n",
    "            plot_losses.append(plot_loss_avg)\n",
    "            plot_loss_total = 0\n",
    "    \n",
    "    if not debug_mode:\n",
    "        showPlot(plot_losses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(encoder, decoder, sentence, max_length=MAX_LENGTH):\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        \n",
    "        input_tensor = tensorFromSentence(input_lang, sentence)\n",
    "        input_length = input_tensor.size()[0]\n",
    "        encoder_hidden = encoder.initHidden()\n",
    "\n",
    "        encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\n",
    "\n",
    "        for ei in range(input_length):\n",
    "            encoder_output, encoder_hidden = encoder(input_tensor[ei], encoder_hidden)\n",
    "            encoder_outputs[ei] += encoder_output[0, 0]\n",
    "\n",
    "        decoder_input = torch.tensor([[SOS_token]], device=device)  # SOS\n",
    "\n",
    "        decoder_hidden = encoder_hidden\n",
    "\n",
    "        decoded_words = []\n",
    "        decoder_attentions = torch.zeros(max_length, max_length)\n",
    "\n",
    "        for di in range(max_length):\n",
    "            \n",
    "            if isinstance(decoder, AttnDecoderRNN):\n",
    "                decoder_output, decoder_hidden, decoder_attention = decoder( decoder_input, decoder_hidden, encoder_outputs)\n",
    "                decoder_attentions[di] = decoder_attention.data\n",
    "            else:\n",
    "                decoder_output, decoder_hidden = decoder( decoder_input, decoder_hidden)\n",
    "            \n",
    "            topv, topi = decoder_output.data.topk(1)\n",
    "            \n",
    "            if topi.item() == EOS_token:\n",
    "                decoded_words.append('<EOS>')\n",
    "                break\n",
    "            else:\n",
    "                decoded_words.append(output_lang.index2word[topi.item()])\n",
    "\n",
    "            decoder_input = topi.squeeze().detach()\n",
    "\n",
    "        return decoded_words, decoder_attentions[:di + 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluateRandomly(encoder, decoder, n=10, seed=12345):\n",
    "    for i in range(n):\n",
    "        random.seed(seed + i)\n",
    "        pair = random.choice(pairs)\n",
    "        print('>', pair[0])\n",
    "        print('=', pair[1])\n",
    "        output_words, attentions = evaluate(encoder, decoder, pair[0])\n",
    "        output_sentence = ' '.join(output_words)\n",
    "        print('<', output_sentence)\n",
    "        print('')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualisaton "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "# plt.switch_backend('agg')\n",
    "import matplotlib.ticker as ticker\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def showPlot(points):\n",
    "    plt.figure()\n",
    "    fig, ax = plt.subplots()\n",
    "    # this locator puts ticks at regular intervals\n",
    "    loc = ticker.MultipleLocator(base=0.2)\n",
    "    ax.yaxis.set_major_locator(loc)\n",
    "    plt.plot(points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Execute Training and Evaluation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set reproducibility.\n",
    "TRAIN_SEED = 42\n",
    "\n",
    "random.seed(TRAIN_SEED)\n",
    "\n",
    "torch.manual_seed(TRAIN_SEED)\n",
    "\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0m 14s (- 36m 19s) (500 0%) 3.5185\n",
      "0m 22s (- 27m 33s) (1000 1%) 3.3353\n",
      "0m 30s (- 24m 33s) (1500 2%) 3.0724\n",
      "0m 37s (- 22m 59s) (2000 2%) 2.9439\n",
      "0m 45s (- 22m 10s) (2500 3%) 2.9132\n",
      "0m 53s (- 21m 31s) (3000 4%) 2.8543\n",
      "1m 1s (- 21m 1s) (3500 4%) 2.7399\n",
      "1m 9s (- 20m 36s) (4000 5%) 2.5961\n",
      "1m 17s (- 20m 17s) (4500 6%) 2.6216\n",
      "1m 25s (- 20m 1s) (5000 6%) 2.6076\n",
      "1m 33s (- 19m 46s) (5500 7%) 2.5676\n",
      "1m 42s (- 19m 33s) (6000 8%) 2.4761\n",
      "1m 50s (- 19m 21s) (6500 8%) 2.4661\n",
      "1m 58s (- 19m 10s) (7000 9%) 2.4499\n",
      "2m 6s (- 18m 57s) (7500 10%) 2.3975\n",
      "2m 14s (- 18m 46s) (8000 10%) 2.3476\n",
      "2m 22s (- 18m 36s) (8500 11%) 2.2955\n",
      "2m 30s (- 18m 25s) (9000 12%) 2.3179\n",
      "2m 38s (- 18m 15s) (9500 12%) 2.2531\n",
      "2m 46s (- 18m 4s) (10000 13%) 2.2226\n",
      "2m 54s (- 17m 54s) (10500 14%) 2.1521\n",
      "3m 2s (- 17m 44s) (11000 14%) 2.1316\n",
      "3m 10s (- 17m 34s) (11500 15%) 2.0186\n",
      "3m 19s (- 17m 25s) (12000 16%) 2.1367\n",
      "3m 27s (- 17m 15s) (12500 16%) 1.9492\n",
      "3m 35s (- 17m 6s) (13000 17%) 2.0758\n",
      "3m 43s (- 16m 56s) (13500 18%) 1.9855\n",
      "3m 51s (- 16m 47s) (14000 18%) 1.9135\n",
      "3m 59s (- 16m 39s) (14500 19%) 1.9359\n",
      "4m 7s (- 16m 30s) (15000 20%) 1.9630\n",
      "4m 15s (- 16m 21s) (15500 20%) 1.9032\n",
      "4m 23s (- 16m 13s) (16000 21%) 1.9056\n",
      "4m 32s (- 16m 4s) (16500 22%) 1.8653\n",
      "4m 40s (- 15m 55s) (17000 22%) 1.8083\n",
      "4m 48s (- 15m 47s) (17500 23%) 1.8223\n",
      "4m 56s (- 15m 38s) (18000 24%) 1.7587\n",
      "5m 4s (- 15m 29s) (18500 24%) 1.7193\n",
      "5m 12s (- 15m 20s) (19000 25%) 1.7298\n",
      "5m 20s (- 15m 11s) (19500 26%) 1.7163\n",
      "5m 28s (- 15m 3s) (20000 26%) 1.6878\n",
      "5m 36s (- 14m 55s) (20500 27%) 1.6309\n",
      "5m 44s (- 14m 46s) (21000 28%) 1.6782\n",
      "5m 53s (- 14m 38s) (21500 28%) 1.7012\n",
      "6m 1s (- 14m 29s) (22000 29%) 1.5970\n",
      "6m 9s (- 14m 21s) (22500 30%) 1.5846\n",
      "6m 17s (- 14m 13s) (23000 30%) 1.5579\n",
      "6m 25s (- 14m 4s) (23500 31%) 1.5735\n",
      "6m 33s (- 13m 56s) (24000 32%) 1.5172\n",
      "6m 42s (- 13m 48s) (24500 32%) 1.4966\n"
     ]
    }
   ],
   "source": [
    "USE_ATTENTION = False\n",
    "EPOCHS= 75000  # 75000, 10000\n",
    "PRINT_EVERY = 500  # 5000, 500\n",
    "\n",
    "hidden_size = 256\n",
    "encoder1 = EncoderRNN(input_lang.n_words, hidden_size).to(device)\n",
    "\n",
    "if USE_ATTENTION:\n",
    "    decoder1 = AttnDecoderRNN(hidden_size, output_lang.n_words, dropout_p=0.1).to(device)\n",
    "else:\n",
    "    decoder1 = DecoderRNN(hidden_size, output_lang.n_words).to(device)\n",
    "\n",
    "\n",
    "TRACE_ON = False  # Print detailed debug info.\n",
    "trainIters(encoder1, decoder1, EPOCHS, print_every=PRINT_EVERY, debug_mode=TRACE_ON)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EVAL_SEED = 12345\n",
    "torch.manual_seed(EVAL_SEED)\n",
    "\n",
    "evaluateRandomly(encoder1, decoder1, seed=EVAL_SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Investigate BATCHING!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:py37_pytorch_tutorials] *",
   "language": "python",
   "name": "conda-env-py37_pytorch_tutorials-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
