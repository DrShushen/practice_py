{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## URLs:\n",
    "GitHub: [https://github.com/gabrielloye/LSTM_Sentiment-Analysis/blob/master/main.ipynb](https://github.com/gabrielloye/LSTM_Sentiment-Analysis/blob/master/main.ipynb)\n",
    "\n",
    "Article: [https://blog.floydhub.com/long-short-term-memory-from-zero-to-hero-with-pytorch/](https://blog.floydhub.com/long-short-term-memory-from-zero-to-hero-with-pytorch/)\n",
    "\n",
    "Data: [https://www.kaggle.com/bittlingmayer/amazonreviews](https://www.kaggle.com/bittlingmayer/amazonreviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Script settings.\n",
    "SMALLER_SAMPLE = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trace(txt, var):\n",
    "    print()\n",
    "    if isinstance(var, (torch.Tensor, np.ndarray)):\n",
    "        print(\"{}   <<{}>>:\\n{}\".format(txt, var.shape, var))\n",
    "    elif isinstance(var, tuple) and isinstance(var[0], (torch.Tensor, np.ndarray)):\n",
    "        print(\"{}:\\n{}\".format(txt, var))\n",
    "        for idx, a in enumerate(var):\n",
    "            print(\"[{}th]  {}   <<{}>>:\\n{}\".format(idx, txt, a.shape, a))\n",
    "    else:\n",
    "        print(\"{}:\\n{}\".format(txt, var))\n",
    "\n",
    "def _print_(txt):\n",
    "    print(\"\\n{}\\n\".format(txt))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "train_sentences   <<(800000, 200)>>:\n",
      "[[    0     0     0 ...   313    15 16999]\n",
      " [    0     0     0 ...   168  2612     2]\n",
      " [    0     0     0 ...    52   264     2]\n",
      " ...\n",
      " [    0     0     0 ...  3764  2894     2]\n",
      " [    0     0     0 ...   610   488     2]\n",
      " [    0     0     0 ...   714   997     2]]\n",
      "\n",
      "train_labels   <<(800000,)>>:\n",
      "[1 1 1 ... 1 1 0]\n",
      "\n",
      "test_sentences   <<(100000, 200)>>:\n",
      "[[    0     0     0 ...  6274  6121     2]\n",
      " [    0     0     0 ...    11    24     2]\n",
      " [    0     0     0 ... 11723   442     2]\n",
      " ...\n",
      " [    0     0     0 ...    81   152     2]\n",
      " [   20   283    29 ... 11765    32     2]\n",
      " [    0     0     0 ...    50  4747     2]]\n",
      "\n",
      "test_labels   <<(100000,)>>:\n",
      "[1 0 1 ... 1 0 1]\n",
      "\n",
      "val_sentences   <<(100000, 200)>>:\n",
      "[[    0     0     0 ...   825    62    32]\n",
      " [    0     0     0 ...   177     9     2]\n",
      " [    0     0     0 ...  3705   517     2]\n",
      " ...\n",
      " [    0     0     0 ...   589    99    62]\n",
      " [    0     0     0 ...  2884  8045     2]\n",
      " [    0     0     0 ...  2721 25644     2]]\n",
      "\n",
      "val_labels   <<(100000,)>>:\n",
      "[1 1 0 ... 0 1 0]\n"
     ]
    }
   ],
   "source": [
    "# Load data.\n",
    "\n",
    "if SMALLER_SAMPLE:\n",
    "    filename = \"./data/processed_small.npz\"\n",
    "else:\n",
    "    filename = \"./data/processed.npz\"\n",
    "\n",
    "npzfile = np.load(filename)\n",
    "train_sentences, train_labels = npzfile[\"train_sentences\"], npzfile[\"train_labels\"]\n",
    "test_sentences, test_labels = npzfile[\"test_sentences\"], npzfile[\"test_labels\"]\n",
    "val_sentences, val_labels = npzfile[\"val_sentences\"], npzfile[\"val_labels\"]\n",
    "\n",
    "txts = (\"train_sentences\", \"train_labels\", \"test_sentences\", \"test_labels\", \"val_sentences\", \"val_labels\")\n",
    "for idx, var in enumerate((train_sentences, train_labels, test_sentences, test_labels, val_sentences, val_labels)):\n",
    "    txt = txts[idx]\n",
    "    trace(txt, var)\n",
    "\n",
    "\n",
    "# Load dictionaries.\n",
    "\n",
    "if SMALLER_SAMPLE:\n",
    "    word2idx_fname = \"./data/word2idx_small.json\"\n",
    "    idx2word_fname = \"./data/idx2word_small.json\"\n",
    "else:\n",
    "    word2idx_fname = \"./data/word2idx.json\"\n",
    "    idx2word_fname = \"./data/idx2word.json\"\n",
    "\n",
    "with open(word2idx_fname, \"r\") as f:\n",
    "    word2idx = json.load(f)\n",
    "with open(idx2word_fname, \"r\") as f:\n",
    "    idx2word = json.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PyTorch Prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reproducibility:\n",
    "seed = 12345\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = TensorDataset(torch.from_numpy(train_sentences), torch.from_numpy(train_labels))\n",
    "val_data = TensorDataset(torch.from_numpy(val_sentences), torch.from_numpy(val_labels))\n",
    "test_data = TensorDataset(torch.from_numpy(test_sentences), torch.from_numpy(test_labels))\n",
    "\n",
    "batch_size = 400\n",
    "\n",
    "train_loader = DataLoader(train_data, shuffle=True, batch_size=batch_size)\n",
    "val_loader = DataLoader(val_data, shuffle=True, batch_size=batch_size)\n",
    "test_loader = DataLoader(test_data, shuffle=True, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU is available\n"
     ]
    }
   ],
   "source": [
    "# torch.cuda.is_available() checks and returns a Boolean True if a GPU is available, else it'll return False\n",
    "is_cuda = torch.cuda.is_available()\n",
    "\n",
    "# If we have a GPU available, we'll set our device to GPU. We'll use this device variable later in our code.\n",
    "if is_cuda:\n",
    "    device = torch.device(\"cuda:1\")  # Use device 1, not 0.\n",
    "    print(\"GPU is available\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(\"GPU not available, CPU used\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x (sentence):  torch.Size([400, 200]) \n",
      "y (label):  torch.Size([400])\n"
     ]
    }
   ],
   "source": [
    "dataiter = iter(train_loader)\n",
    "sample_x, sample_y = dataiter.next()\n",
    "\n",
    "print(\"x (sentence): \", sample_x.shape, \"\\ny (label): \", sample_y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Model\n",
    "\n",
    "Diagram:\n",
    "![img](./content/ModelArchitecture.JPG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SentimentNet(nn.Module):\n",
    "    \n",
    "    def __init__(self, vocab_size, output_size, embedding_dim, hidden_dim, n_layers, drop_prob=0.5):\n",
    "        super(SentimentNet, self).__init__()\n",
    "        self.output_size = output_size\n",
    "        self.n_layers = n_layers\n",
    "        self.hidden_dim = hidden_dim\n",
    "        \n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.lstm = nn.LSTM(embedding_dim, hidden_dim, n_layers, dropout=drop_prob, batch_first=True)\n",
    "        self.dropout = nn.Dropout(0.2)\n",
    "        self.fc = nn.Linear(hidden_dim, output_size)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        \n",
    "    def forward(self, x, hidden, trace_on=False):\n",
    "        if trace_on:\n",
    "            _print_(\"--- forward() ---\")\n",
    "        \n",
    "        batch_size = x.size(0)\n",
    "        if trace_on:\n",
    "            trace(\"batch_size = x.size(0)\", batch_size)\n",
    "        x = x.long()\n",
    "        if trace_on:\n",
    "            trace(\"x = x.long()\", x)\n",
    "        embeds = self.embedding(x)\n",
    "        if trace_on:\n",
    "            trace(\"embeds = self.embedding(x)\", embeds)\n",
    "        lstm_out, hidden = self.lstm(embeds, hidden)\n",
    "        if trace_on:\n",
    "            trace(\"lstm_out <- self.lstm(embeds, hidden)\", lstm_out)\n",
    "            trace(\"hidden <- self.lstm(embeds, hidden)\", hidden)\n",
    "        lstm_out = lstm_out.contiguous().view(-1, self.hidden_dim)  # contiguous() is related to memory contiguity: https://pytorch.org/docs/stable/tensors.html#torch.Tensor.contiguous\n",
    "        if trace_on:\n",
    "            trace(\"lstm_out = lstm_out.contiguous().view(-1, self.hidden_dim)\", lstm_out)\n",
    "        \n",
    "        out = self.dropout(lstm_out)\n",
    "        if trace_on:\n",
    "            trace(\"out = self.dropout(lstm_out)\", out)\n",
    "        out = self.fc(out)\n",
    "        if trace_on:\n",
    "            trace(\"out = self.fc(out)\", out)\n",
    "        out = self.sigmoid(out)\n",
    "        if trace_on:\n",
    "            trace(\"out = self.sigmoid(out)\", out)\n",
    "        \n",
    "        out = out.view(batch_size, -1)\n",
    "        if trace_on:\n",
    "            trace(\"out = out.view(batch_size, -1)\", out)\n",
    "        out = out[:,-1]\n",
    "        if trace_on:\n",
    "            trace(\"out = out[:,-1]\", out)\n",
    "            _print_(\"--- <end> forward() ---\")\n",
    "            \n",
    "        return out, hidden\n",
    "    \n",
    "    def init_hidden(self, batch_size, trace_on=False):\n",
    "        if trace_on:\n",
    "            _print_(\"--- init_hidden() ---\")\n",
    "        \n",
    "        weight = next(self.parameters()).data\n",
    "        if trace_on:\n",
    "            trace(\"weight = next(self.parameters()).data\", weight)\n",
    "        \n",
    "        hidden = (weight.new(self.n_layers, batch_size, self.hidden_dim).zero_().to(device),\n",
    "                      weight.new(self.n_layers, batch_size, self.hidden_dim).zero_().to(device))\n",
    "        if trace_on:\n",
    "            trace(\"hidden = ...\", hidden)\n",
    "            _print_(\"--- <end> init_hidden() ---\")\n",
    "        \n",
    "        return hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SentimentNet(\n",
      "  (embedding): Embedding(225536, 400)\n",
      "  (lstm): LSTM(400, 512, num_layers=2, batch_first=True, dropout=0.5)\n",
      "  (dropout): Dropout(p=0.2, inplace=False)\n",
      "  (fc): Linear(in_features=512, out_features=1, bias=True)\n",
      "  (sigmoid): Sigmoid()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "vocab_size = len(word2idx) + 1\n",
    "output_size = 1\n",
    "embedding_dim = 400\n",
    "hidden_dim = 512\n",
    "n_layers = 2\n",
    "\n",
    "model = SentimentNet(vocab_size, output_size, embedding_dim, hidden_dim, n_layers)\n",
    "model.to(device)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training variables.\n",
    "\n",
    "lr=0.005\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- init_hidden() ---\n",
      "\n",
      "\n",
      "weight = next(self.parameters()).data   <<torch.Size([225536, 400])>>:\n",
      "tensor([[ 2.1229, -0.3070,  1.1609,  ...,  1.1793,  0.1334, -1.1225],\n",
      "        [-0.0633,  3.3590,  0.0892,  ..., -0.3579,  0.7567, -0.0280],\n",
      "        [ 0.0372, -1.5348, -1.0914,  ...,  0.2764, -1.5753,  0.3745],\n",
      "        ...,\n",
      "        [-0.5144,  1.7953,  1.6041,  ..., -0.0379, -0.4028, -0.4660],\n",
      "        [ 0.4156,  2.0037,  1.1897,  ..., -1.3525,  0.6580,  0.3276],\n",
      "        [ 1.6801, -1.6561,  0.8391,  ...,  0.7824, -0.4503, -0.5420]],\n",
      "       device='cuda:1')\n",
      "\n",
      "hidden = ...:\n",
      "(tensor([[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         ...,\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         ...,\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.]]], device='cuda:1'), tensor([[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         ...,\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         ...,\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.]]], device='cuda:1'))\n",
      "[0th]  hidden = ...   <<torch.Size([2, 400, 512])>>:\n",
      "tensor([[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         ...,\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         ...,\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.]]], device='cuda:1')\n",
      "[1th]  hidden = ...   <<torch.Size([2, 400, 512])>>:\n",
      "tensor([[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         ...,\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         ...,\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.]]], device='cuda:1')\n",
      "\n",
      "--- <end> init_hidden() ---\n",
      "\n",
      "\n",
      "--- forward() ---\n",
      "\n",
      "\n",
      "batch_size = x.size(0):\n",
      "400\n",
      "\n",
      "x = x.long()   <<torch.Size([400, 200])>>:\n",
      "tensor([[   0,    0,    0,  ...,  264,  455,   44],\n",
      "        [   0,    0,    0,  ...,   15,   15,   15],\n",
      "        [   0,    0,    0,  ...,  282,   55,    2],\n",
      "        ...,\n",
      "        [   0,    0,    0,  ...,    3, 1485,    2],\n",
      "        [   0,    0,    0,  ...,   42,   60,   15],\n",
      "        [   0,    0,    0,  ...,  429,    8,    2]], device='cuda:1')\n",
      "\n",
      "embeds = self.embedding(x)   <<torch.Size([400, 200, 400])>>:\n",
      "tensor([[[ 2.1229, -0.3070,  1.1609,  ...,  1.1793,  0.1334, -1.1225],\n",
      "         [ 2.1229, -0.3070,  1.1609,  ...,  1.1793,  0.1334, -1.1225],\n",
      "         [ 2.1229, -0.3070,  1.1609,  ...,  1.1793,  0.1334, -1.1225],\n",
      "         ...,\n",
      "         [ 1.0161,  0.4106, -1.1320,  ..., -1.4019, -0.3344, -1.6976],\n",
      "         [-0.5674, -0.1426,  3.0948,  ..., -0.0875,  0.2729, -0.6400],\n",
      "         [-1.7717,  0.6062,  0.4552,  ...,  0.7830, -0.7043,  0.2088]],\n",
      "\n",
      "        [[ 2.1229, -0.3070,  1.1609,  ...,  1.1793,  0.1334, -1.1225],\n",
      "         [ 2.1229, -0.3070,  1.1609,  ...,  1.1793,  0.1334, -1.1225],\n",
      "         [ 2.1229, -0.3070,  1.1609,  ...,  1.1793,  0.1334, -1.1225],\n",
      "         ...,\n",
      "         [-0.0829, -0.9813,  0.9270,  ...,  1.3406, -2.6661,  0.6315],\n",
      "         [-0.0829, -0.9813,  0.9270,  ...,  1.3406, -2.6661,  0.6315],\n",
      "         [-0.0829, -0.9813,  0.9270,  ...,  1.3406, -2.6661,  0.6315]],\n",
      "\n",
      "        [[ 2.1229, -0.3070,  1.1609,  ...,  1.1793,  0.1334, -1.1225],\n",
      "         [ 2.1229, -0.3070,  1.1609,  ...,  1.1793,  0.1334, -1.1225],\n",
      "         [ 2.1229, -0.3070,  1.1609,  ...,  1.1793,  0.1334, -1.1225],\n",
      "         ...,\n",
      "         [-1.0023,  1.5222,  0.1225,  ..., -1.6502,  1.2914, -1.6238],\n",
      "         [-1.0078,  0.6412, -0.1613,  ...,  0.2587, -0.8419,  0.4590],\n",
      "         [ 0.0372, -1.5348, -1.0914,  ...,  0.2764, -1.5753,  0.3745]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 2.1229, -0.3070,  1.1609,  ...,  1.1793,  0.1334, -1.1225],\n",
      "         [ 2.1229, -0.3070,  1.1609,  ...,  1.1793,  0.1334, -1.1225],\n",
      "         [ 2.1229, -0.3070,  1.1609,  ...,  1.1793,  0.1334, -1.1225],\n",
      "         ...,\n",
      "         [-0.0291,  0.1073,  1.1334,  ..., -1.2672, -1.7359,  0.9992],\n",
      "         [ 1.7865, -1.0752, -0.1259,  ..., -0.1357,  0.4107, -1.1789],\n",
      "         [ 0.0372, -1.5348, -1.0914,  ...,  0.2764, -1.5753,  0.3745]],\n",
      "\n",
      "        [[ 2.1229, -0.3070,  1.1609,  ...,  1.1793,  0.1334, -1.1225],\n",
      "         [ 2.1229, -0.3070,  1.1609,  ...,  1.1793,  0.1334, -1.1225],\n",
      "         [ 2.1229, -0.3070,  1.1609,  ...,  1.1793,  0.1334, -1.1225],\n",
      "         ...,\n",
      "         [-1.7162,  0.4349, -1.5245,  ..., -1.0130, -0.5171,  1.0221],\n",
      "         [ 1.8723,  1.4282, -0.6279,  ..., -0.7203, -0.4400, -0.4664],\n",
      "         [-0.0829, -0.9813,  0.9270,  ...,  1.3406, -2.6661,  0.6315]],\n",
      "\n",
      "        [[ 2.1229, -0.3070,  1.1609,  ...,  1.1793,  0.1334, -1.1225],\n",
      "         [ 2.1229, -0.3070,  1.1609,  ...,  1.1793,  0.1334, -1.1225],\n",
      "         [ 2.1229, -0.3070,  1.1609,  ...,  1.1793,  0.1334, -1.1225],\n",
      "         ...,\n",
      "         [-0.0146,  1.6612,  0.4838,  ...,  0.5386,  1.2408, -3.0154],\n",
      "         [-0.4441, -1.5032,  0.2710,  ...,  1.1420, -1.6331, -1.9207],\n",
      "         [ 0.0372, -1.5348, -1.0914,  ...,  0.2764, -1.5753,  0.3745]]],\n",
      "       device='cuda:1', grad_fn=<EmbeddingBackward>)\n",
      "\n",
      "lstm_out <- self.lstm(embeds, hidden)   <<torch.Size([400, 200, 512])>>:\n",
      "tensor([[[-2.2366e-02,  1.3005e-02,  2.1905e-03,  ...,  2.6753e-03,\n",
      "           1.2117e-02, -7.4110e-03],\n",
      "         [-6.4682e-03, -1.9356e-02,  2.2997e-02,  ...,  8.6224e-05,\n",
      "           1.4198e-02, -1.9498e-02],\n",
      "         [-1.0133e-02, -2.3501e-02, -4.2208e-03,  ...,  1.2702e-02,\n",
      "          -1.0280e-02, -8.8895e-02],\n",
      "         ...,\n",
      "         [-1.1051e-02,  2.1812e-02,  5.1413e-03,  ..., -4.8414e-02,\n",
      "           1.9495e-02,  5.1112e-02],\n",
      "         [-2.5204e-02, -3.4046e-03,  1.3458e-02,  ..., -4.1875e-02,\n",
      "           3.0217e-02, -3.0007e-02],\n",
      "         [ 1.9563e-02, -3.6062e-02,  3.6566e-02,  ..., -2.1302e-02,\n",
      "           3.3873e-02, -8.5330e-02]],\n",
      "\n",
      "        [[-1.4699e-02,  3.4651e-03,  1.3257e-02,  ...,  1.9957e-02,\n",
      "           3.6932e-03, -1.2296e-02],\n",
      "         [ 1.6121e-02, -1.2179e-02, -2.6911e-02,  ...,  2.0779e-02,\n",
      "           2.3569e-02, -2.6269e-02],\n",
      "         [ 1.3930e-02,  2.2714e-02, -2.6911e-02,  ..., -1.5490e-02,\n",
      "           3.0927e-02, -6.1749e-02],\n",
      "         ...,\n",
      "         [ 5.8909e-02, -9.3955e-03,  1.3261e-02,  ..., -4.3581e-02,\n",
      "           6.7705e-02,  6.8365e-03],\n",
      "         [ 6.4740e-02, -4.8569e-02,  6.4012e-02,  ..., -6.1788e-02,\n",
      "           5.1896e-02,  2.7027e-02],\n",
      "         [ 4.9831e-02, -3.0513e-02,  4.1320e-02,  ..., -6.5627e-02,\n",
      "           1.0575e-01,  1.9051e-02]],\n",
      "\n",
      "        [[-1.3335e-02, -7.1060e-03,  6.1462e-03,  ...,  1.1853e-03,\n",
      "           8.2651e-03, -3.0874e-02],\n",
      "         [-9.8926e-04, -1.5352e-02,  1.0482e-02,  ..., -7.6224e-03,\n",
      "           2.8388e-02, -2.3581e-03],\n",
      "         [ 1.0798e-02, -7.6370e-03,  6.5991e-03,  ..., -2.9886e-02,\n",
      "           6.6538e-02, -2.5199e-02],\n",
      "         ...,\n",
      "         [ 3.2499e-02, -6.2695e-02,  1.2102e-02,  ..., -3.0389e-02,\n",
      "          -7.2473e-03,  8.3547e-03],\n",
      "         [ 3.5767e-02, -3.4606e-02, -8.9081e-03,  ..., -5.9544e-02,\n",
      "           9.9856e-03, -5.0871e-03],\n",
      "         [ 3.4966e-02, -3.2596e-02, -7.8929e-03,  ..., -5.9395e-02,\n",
      "           5.0353e-02, -1.5630e-02]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-1.5713e-03, -2.9257e-03,  8.2309e-03,  ..., -1.2104e-02,\n",
      "           2.5629e-02, -7.4964e-03],\n",
      "         [-1.5993e-02, -3.3729e-03, -2.1980e-02,  ...,  4.3735e-03,\n",
      "           5.3645e-02, -3.0652e-02],\n",
      "         [-1.7092e-02, -4.1007e-02, -1.6181e-02,  ..., -3.5865e-03,\n",
      "           3.3271e-02,  4.6571e-03],\n",
      "         ...,\n",
      "         [ 1.2877e-02,  2.9357e-02, -7.2095e-03,  ..., -3.6124e-02,\n",
      "           6.0567e-02,  3.4099e-02],\n",
      "         [ 1.7353e-02, -1.7210e-02,  1.3166e-02,  ..., -7.9541e-02,\n",
      "           3.1131e-02,  3.3230e-02],\n",
      "         [-3.5229e-03, -4.0718e-02,  8.4814e-03,  ..., -8.7158e-02,\n",
      "           1.0216e-02,  3.5552e-03]],\n",
      "\n",
      "        [[ 1.0776e-02, -1.1241e-02, -1.9938e-02,  ..., -3.0265e-02,\n",
      "           8.3338e-03, -6.9005e-03],\n",
      "         [-1.2231e-02,  8.5445e-03, -2.1430e-02,  ..., -2.4404e-02,\n",
      "           1.6649e-02, -1.7903e-02],\n",
      "         [-4.5328e-03,  3.1119e-02, -6.1348e-02,  ..., -4.1771e-02,\n",
      "          -5.7387e-02, -3.8359e-02],\n",
      "         ...,\n",
      "         [-2.7328e-03, -1.5780e-02,  8.4818e-03,  ..., -1.5405e-02,\n",
      "           8.3756e-02, -1.6085e-02],\n",
      "         [ 1.0615e-02, -9.1861e-03,  1.6048e-02,  ..., -6.2865e-02,\n",
      "           8.1090e-02,  1.5395e-02],\n",
      "         [ 8.3812e-03, -1.3095e-02,  3.5576e-02,  ..., -4.4618e-02,\n",
      "           1.0529e-01,  5.5694e-02]],\n",
      "\n",
      "        [[ 9.5698e-03, -2.0971e-02,  7.2718e-03,  ..., -1.7019e-02,\n",
      "           3.2408e-02,  4.1780e-04],\n",
      "         [-1.6327e-02, -2.6808e-02,  1.7658e-02,  ...,  2.4279e-03,\n",
      "          -4.2116e-03,  7.6854e-03],\n",
      "         [-6.8611e-03, -3.5883e-02, -4.4204e-02,  ..., -3.4336e-02,\n",
      "           3.9536e-02, -3.6343e-02],\n",
      "         ...,\n",
      "         [ 5.2313e-02, -4.9902e-02, -2.5045e-02,  ..., -7.5904e-02,\n",
      "          -1.4772e-02, -3.2924e-02],\n",
      "         [ 5.6872e-02, -4.0680e-02, -5.1220e-02,  ..., -8.7438e-02,\n",
      "          -2.0591e-02, -8.6992e-02],\n",
      "         [ 3.7416e-02, -7.2509e-02, -6.2765e-02,  ..., -6.7904e-02,\n",
      "          -5.9152e-02, -8.7659e-02]]], device='cuda:1',\n",
      "       grad_fn=<CudnnRnnBackward>)\n",
      "\n",
      "hidden <- self.lstm(embeds, hidden):\n",
      "(tensor([[[-0.0686, -0.0315,  0.0302,  ...,  0.0225,  0.0336,  0.1372],\n",
      "         [ 0.0148, -0.1842,  0.2714,  ..., -0.2653, -0.0271,  0.0731],\n",
      "         [-0.1176,  0.1365,  0.1327,  ..., -0.1242,  0.1200, -0.1115],\n",
      "         ...,\n",
      "         [-0.1863,  0.1730,  0.1720,  ..., -0.0917, -0.1373, -0.0696],\n",
      "         [-0.0648, -0.0674,  0.2431,  ..., -0.2139, -0.0537, -0.0254],\n",
      "         [ 0.0901,  0.0649,  0.0522,  ..., -0.2163, -0.1588,  0.0509]],\n",
      "\n",
      "        [[ 0.0196, -0.0361,  0.0366,  ..., -0.0213,  0.0339, -0.0853],\n",
      "         [ 0.0498, -0.0305,  0.0413,  ..., -0.0656,  0.1058,  0.0191],\n",
      "         [ 0.0350, -0.0326, -0.0079,  ..., -0.0594,  0.0504, -0.0156],\n",
      "         ...,\n",
      "         [-0.0035, -0.0407,  0.0085,  ..., -0.0872,  0.0102,  0.0036],\n",
      "         [ 0.0084, -0.0131,  0.0356,  ..., -0.0446,  0.1053,  0.0557],\n",
      "         [ 0.0374, -0.0725, -0.0628,  ..., -0.0679, -0.0592, -0.0877]]],\n",
      "       device='cuda:1', grad_fn=<CudnnRnnBackward>), tensor([[[-0.1428, -0.0554,  0.0864,  ...,  0.0500,  0.1289,  0.4385],\n",
      "         [ 0.0296, -0.2971,  0.5960,  ..., -0.5949, -0.0832,  0.1812],\n",
      "         [-0.2100,  0.2895,  0.2848,  ..., -0.1893,  0.2008, -0.2617],\n",
      "         ...,\n",
      "         [-0.3583,  0.4021,  0.3727,  ..., -0.1423, -0.2318, -0.1688],\n",
      "         [-0.1316, -0.1116,  0.5314,  ..., -0.4623, -0.1804, -0.0568],\n",
      "         [ 0.1639,  0.1309,  0.1103,  ..., -0.3280, -0.2787,  0.1123]],\n",
      "\n",
      "        [[ 0.0431, -0.0681,  0.0739,  ..., -0.0484,  0.0713, -0.1728],\n",
      "         [ 0.1082, -0.0547,  0.0809,  ..., -0.1225,  0.1995,  0.0325],\n",
      "         [ 0.0700, -0.0701, -0.0162,  ..., -0.1140,  0.0995, -0.0320],\n",
      "         ...,\n",
      "         [-0.0071, -0.0848,  0.0146,  ..., -0.1683,  0.0204,  0.0070],\n",
      "         [ 0.0181, -0.0245,  0.0665,  ..., -0.0826,  0.2137,  0.1070],\n",
      "         [ 0.0839, -0.1579, -0.1279,  ..., -0.1243, -0.1183, -0.1887]]],\n",
      "       device='cuda:1', grad_fn=<CudnnRnnBackward>))\n",
      "[0th]  hidden <- self.lstm(embeds, hidden)   <<torch.Size([2, 400, 512])>>:\n",
      "tensor([[[-0.0686, -0.0315,  0.0302,  ...,  0.0225,  0.0336,  0.1372],\n",
      "         [ 0.0148, -0.1842,  0.2714,  ..., -0.2653, -0.0271,  0.0731],\n",
      "         [-0.1176,  0.1365,  0.1327,  ..., -0.1242,  0.1200, -0.1115],\n",
      "         ...,\n",
      "         [-0.1863,  0.1730,  0.1720,  ..., -0.0917, -0.1373, -0.0696],\n",
      "         [-0.0648, -0.0674,  0.2431,  ..., -0.2139, -0.0537, -0.0254],\n",
      "         [ 0.0901,  0.0649,  0.0522,  ..., -0.2163, -0.1588,  0.0509]],\n",
      "\n",
      "        [[ 0.0196, -0.0361,  0.0366,  ..., -0.0213,  0.0339, -0.0853],\n",
      "         [ 0.0498, -0.0305,  0.0413,  ..., -0.0656,  0.1058,  0.0191],\n",
      "         [ 0.0350, -0.0326, -0.0079,  ..., -0.0594,  0.0504, -0.0156],\n",
      "         ...,\n",
      "         [-0.0035, -0.0407,  0.0085,  ..., -0.0872,  0.0102,  0.0036],\n",
      "         [ 0.0084, -0.0131,  0.0356,  ..., -0.0446,  0.1053,  0.0557],\n",
      "         [ 0.0374, -0.0725, -0.0628,  ..., -0.0679, -0.0592, -0.0877]]],\n",
      "       device='cuda:1', grad_fn=<CudnnRnnBackward>)\n",
      "[1th]  hidden <- self.lstm(embeds, hidden)   <<torch.Size([2, 400, 512])>>:\n",
      "tensor([[[-0.1428, -0.0554,  0.0864,  ...,  0.0500,  0.1289,  0.4385],\n",
      "         [ 0.0296, -0.2971,  0.5960,  ..., -0.5949, -0.0832,  0.1812],\n",
      "         [-0.2100,  0.2895,  0.2848,  ..., -0.1893,  0.2008, -0.2617],\n",
      "         ...,\n",
      "         [-0.3583,  0.4021,  0.3727,  ..., -0.1423, -0.2318, -0.1688],\n",
      "         [-0.1316, -0.1116,  0.5314,  ..., -0.4623, -0.1804, -0.0568],\n",
      "         [ 0.1639,  0.1309,  0.1103,  ..., -0.3280, -0.2787,  0.1123]],\n",
      "\n",
      "        [[ 0.0431, -0.0681,  0.0739,  ..., -0.0484,  0.0713, -0.1728],\n",
      "         [ 0.1082, -0.0547,  0.0809,  ..., -0.1225,  0.1995,  0.0325],\n",
      "         [ 0.0700, -0.0701, -0.0162,  ..., -0.1140,  0.0995, -0.0320],\n",
      "         ...,\n",
      "         [-0.0071, -0.0848,  0.0146,  ..., -0.1683,  0.0204,  0.0070],\n",
      "         [ 0.0181, -0.0245,  0.0665,  ..., -0.0826,  0.2137,  0.1070],\n",
      "         [ 0.0839, -0.1579, -0.1279,  ..., -0.1243, -0.1183, -0.1887]]],\n",
      "       device='cuda:1', grad_fn=<CudnnRnnBackward>)\n",
      "\n",
      "lstm_out = lstm_out.contiguous().view(-1, self.hidden_dim)   <<torch.Size([80000, 512])>>:\n",
      "tensor([[-2.2366e-02,  1.3005e-02,  2.1905e-03,  ...,  2.6753e-03,\n",
      "          1.2117e-02, -7.4110e-03],\n",
      "        [-6.4682e-03, -1.9356e-02,  2.2997e-02,  ...,  8.6224e-05,\n",
      "          1.4198e-02, -1.9498e-02],\n",
      "        [-1.0133e-02, -2.3501e-02, -4.2208e-03,  ...,  1.2702e-02,\n",
      "         -1.0280e-02, -8.8895e-02],\n",
      "        ...,\n",
      "        [ 5.2313e-02, -4.9902e-02, -2.5045e-02,  ..., -7.5904e-02,\n",
      "         -1.4772e-02, -3.2924e-02],\n",
      "        [ 5.6872e-02, -4.0680e-02, -5.1220e-02,  ..., -8.7438e-02,\n",
      "         -2.0591e-02, -8.6992e-02],\n",
      "        [ 3.7416e-02, -7.2509e-02, -6.2765e-02,  ..., -6.7904e-02,\n",
      "         -5.9152e-02, -8.7659e-02]], device='cuda:1', grad_fn=<ViewBackward>)\n",
      "\n",
      "out = self.dropout(lstm_out)   <<torch.Size([80000, 512])>>:\n",
      "tensor([[ 0.0000e+00,  1.6256e-02,  2.7382e-03,  ...,  0.0000e+00,\n",
      "          0.0000e+00, -9.2637e-03],\n",
      "        [-8.0852e-03, -2.4195e-02,  2.8746e-02,  ...,  1.0778e-04,\n",
      "          1.7748e-02, -2.4373e-02],\n",
      "        [-1.2667e-02, -2.9377e-02, -5.2760e-03,  ...,  1.5878e-02,\n",
      "         -1.2850e-02, -1.1112e-01],\n",
      "        ...,\n",
      "        [ 6.5391e-02,  0.0000e+00, -3.1307e-02,  ..., -9.4880e-02,\n",
      "         -1.8465e-02, -4.1155e-02],\n",
      "        [ 7.1090e-02, -5.0850e-02,  0.0000e+00,  ...,  0.0000e+00,\n",
      "          0.0000e+00, -1.0874e-01],\n",
      "        [ 4.6769e-02, -9.0637e-02, -7.8456e-02,  ..., -8.4880e-02,\n",
      "         -7.3940e-02, -1.0957e-01]], device='cuda:1',\n",
      "       grad_fn=<FusedDropoutBackward>)\n",
      "\n",
      "out = self.fc(out)   <<torch.Size([80000, 1])>>:\n",
      "tensor([[-0.0392],\n",
      "        [-0.0782],\n",
      "        [-0.0890],\n",
      "        ...,\n",
      "        [-0.0654],\n",
      "        [-0.0765],\n",
      "        [-0.0586]], device='cuda:1', grad_fn=<AddmmBackward>)\n",
      "\n",
      "out = self.sigmoid(out)   <<torch.Size([80000, 1])>>:\n",
      "tensor([[0.4902],\n",
      "        [0.4804],\n",
      "        [0.4778],\n",
      "        ...,\n",
      "        [0.4836],\n",
      "        [0.4809],\n",
      "        [0.4854]], device='cuda:1', grad_fn=<SigmoidBackward>)\n",
      "\n",
      "out = out.view(batch_size, -1)   <<torch.Size([400, 200])>>:\n",
      "tensor([[0.4902, 0.4804, 0.4778,  ..., 0.4913, 0.4953, 0.4972],\n",
      "        [0.4947, 0.4874, 0.4805,  ..., 0.4881, 0.4905, 0.4892],\n",
      "        [0.4906, 0.4807, 0.4808,  ..., 0.4899, 0.4914, 0.4884],\n",
      "        ...,\n",
      "        [0.4928, 0.4834, 0.4820,  ..., 0.4904, 0.4870, 0.4884],\n",
      "        [0.4906, 0.4814, 0.4776,  ..., 0.4986, 0.4930, 0.4962],\n",
      "        [0.4926, 0.4894, 0.4971,  ..., 0.4836, 0.4809, 0.4854]],\n",
      "       device='cuda:1', grad_fn=<ViewBackward>)\n",
      "\n",
      "out = out[:,-1]   <<torch.Size([400])>>:\n",
      "tensor([0.4972, 0.4892, 0.4884, 0.4864, 0.4865, 0.4989, 0.4963, 0.4961, 0.4981,\n",
      "        0.4941, 0.4924, 0.4856, 0.4963, 0.4963, 0.4939, 0.4950, 0.4881, 0.4906,\n",
      "        0.4979, 0.4963, 0.4856, 0.4918, 0.4851, 0.4898, 0.5015, 0.4838, 0.4955,\n",
      "        0.4956, 0.4933, 0.4997, 0.5058, 0.4902, 0.4907, 0.4892, 0.4925, 0.4965,\n",
      "        0.4975, 0.4932, 0.4955, 0.4904, 0.4945, 0.4939, 0.4965, 0.5014, 0.4882,\n",
      "        0.4905, 0.4963, 0.4870, 0.4902, 0.4928, 0.4978, 0.4911, 0.4958, 0.4915,\n",
      "        0.4850, 0.5047, 0.4880, 0.4968, 0.5021, 0.4963, 0.4917, 0.4967, 0.4917,\n",
      "        0.4953, 0.5038, 0.4938, 0.4799, 0.4998, 0.4982, 0.4950, 0.4989, 0.4885,\n",
      "        0.4853, 0.5014, 0.4954, 0.4937, 0.4868, 0.5033, 0.4943, 0.4935, 0.4942,\n",
      "        0.4940, 0.4813, 0.4866, 0.4944, 0.4870, 0.4936, 0.5013, 0.4952, 0.4956,\n",
      "        0.4926, 0.4905, 0.4921, 0.4937, 0.4997, 0.4953, 0.4958, 0.4825, 0.4872,\n",
      "        0.4886, 0.4946, 0.4962, 0.4924, 0.4988, 0.4896, 0.4908, 0.4928, 0.4884,\n",
      "        0.4850, 0.4945, 0.5049, 0.4997, 0.4934, 0.4899, 0.4956, 0.5005, 0.4933,\n",
      "        0.4910, 0.4910, 0.5020, 0.4933, 0.5001, 0.4968, 0.4874, 0.4883, 0.4983,\n",
      "        0.4968, 0.4955, 0.4921, 0.4966, 0.4865, 0.4950, 0.4952, 0.4924, 0.4899,\n",
      "        0.5064, 0.4969, 0.4959, 0.4946, 0.4967, 0.4918, 0.4908, 0.4915, 0.4983,\n",
      "        0.4901, 0.4905, 0.4993, 0.4822, 0.4953, 0.4995, 0.5007, 0.4940, 0.4956,\n",
      "        0.4886, 0.4909, 0.4874, 0.4992, 0.4838, 0.4903, 0.4960, 0.4991, 0.4938,\n",
      "        0.4914, 0.4903, 0.4937, 0.4928, 0.4880, 0.4852, 0.5001, 0.4870, 0.4945,\n",
      "        0.4927, 0.4864, 0.4799, 0.4978, 0.4809, 0.4945, 0.4977, 0.4791, 0.4994,\n",
      "        0.4940, 0.4990, 0.4916, 0.4918, 0.4903, 0.4954, 0.4942, 0.4875, 0.4830,\n",
      "        0.4895, 0.4949, 0.4910, 0.4982, 0.4870, 0.4999, 0.4980, 0.4959, 0.4821,\n",
      "        0.4916, 0.4925, 0.4977, 0.4987, 0.4971, 0.4865, 0.4880, 0.4981, 0.4972,\n",
      "        0.4951, 0.4920, 0.4863, 0.4953, 0.4916, 0.4908, 0.4889, 0.4958, 0.4980,\n",
      "        0.4896, 0.4803, 0.4887, 0.4878, 0.4933, 0.4952, 0.4903, 0.4867, 0.4951,\n",
      "        0.4873, 0.4914, 0.4947, 0.4932, 0.4907, 0.4855, 0.4880, 0.4903, 0.4951,\n",
      "        0.4865, 0.4926, 0.4916, 0.4867, 0.4846, 0.4913, 0.5015, 0.4881, 0.4956,\n",
      "        0.4951, 0.4938, 0.4914, 0.4947, 0.4895, 0.4950, 0.4943, 0.4914, 0.4951,\n",
      "        0.4904, 0.5076, 0.4893, 0.4935, 0.4895, 0.4983, 0.4907, 0.4950, 0.5014,\n",
      "        0.4932, 0.4867, 0.4871, 0.4957, 0.4860, 0.4865, 0.4968, 0.4985, 0.4892,\n",
      "        0.4920, 0.4848, 0.4972, 0.4904, 0.4941, 0.4968, 0.4942, 0.4946, 0.4923,\n",
      "        0.4944, 0.4972, 0.4875, 0.4994, 0.4964, 0.4874, 0.4888, 0.4946, 0.4825,\n",
      "        0.4913, 0.4966, 0.4956, 0.4910, 0.5032, 0.4875, 0.4935, 0.4889, 0.4953,\n",
      "        0.4951, 0.4949, 0.4838, 0.5056, 0.4965, 0.4936, 0.4982, 0.4941, 0.5068,\n",
      "        0.5019, 0.4915, 0.4964, 0.4919, 0.4918, 0.4948, 0.4932, 0.4894, 0.4932,\n",
      "        0.4927, 0.4932, 0.5009, 0.4880, 0.4897, 0.4878, 0.4875, 0.4887, 0.4851,\n",
      "        0.4939, 0.5026, 0.5005, 0.4898, 0.4949, 0.4878, 0.5006, 0.4921, 0.4922,\n",
      "        0.4917, 0.4947, 0.4876, 0.4837, 0.4903, 0.4927, 0.4904, 0.4943, 0.4982,\n",
      "        0.4948, 0.4951, 0.5028, 0.4922, 0.4918, 0.4948, 0.4802, 0.4817, 0.4931,\n",
      "        0.4857, 0.4997, 0.4913, 0.4904, 0.4915, 0.4944, 0.4965, 0.4971, 0.5066,\n",
      "        0.4863, 0.4957, 0.4984, 0.4861, 0.4916, 0.4978, 0.4918, 0.4878, 0.4905,\n",
      "        0.4891, 0.5007, 0.4954, 0.4962, 0.4986, 0.4978, 0.4945, 0.4921, 0.4936,\n",
      "        0.5062, 0.4976, 0.4929, 0.5005, 0.4973, 0.5015, 0.4967, 0.4971, 0.4995,\n",
      "        0.4959, 0.4996, 0.4854, 0.4899, 0.4889, 0.4886, 0.4824, 0.4963, 0.4926,\n",
      "        0.5067, 0.4884, 0.4962, 0.4854], device='cuda:1',\n",
      "       grad_fn=<SelectBackward>)\n",
      "\n",
      "--- <end> forward() ---\n",
      "\n",
      "Epoch: 1/2... Step: 1000... Loss: 0.195766... Val Loss: 0.193469\n",
      "Validation loss decreased (inf --> 0.193469).  Saving model ...\n",
      "Epoch: 1/2... Step: 2000... Loss: 0.175454... Val Loss: 0.184291\n",
      "Validation loss decreased (0.193469 --> 0.184291).  Saving model ...\n",
      "Epoch: 2/2... Step: 3000... Loss: 0.131830... Val Loss: 0.184083\n",
      "Validation loss decreased (0.184291 --> 0.184083).  Saving model ...\n",
      "Epoch: 2/2... Step: 4000... Loss: 0.131640... Val Loss: 0.183054\n",
      "Validation loss decreased (0.184083 --> 0.183054).  Saving model ...\n"
     ]
    }
   ],
   "source": [
    "epochs = 2\n",
    "counter = 0\n",
    "clip = 5\n",
    "valid_loss_min = np.Inf\n",
    "\n",
    "if SMALLER_SAMPLE:\n",
    "    print_every = 10\n",
    "else:\n",
    "    print_every = 1000\n",
    "\n",
    "\n",
    "model.train()\n",
    "\n",
    "for i in range(epochs):\n",
    "    \n",
    "    trace_on = False\n",
    "    if i == 0:\n",
    "        trace_on = True\n",
    "            \n",
    "    h = model.init_hidden(batch_size, trace_on=trace_on)\n",
    "    \n",
    "    for idx, (inputs, labels) in enumerate(train_loader):\n",
    "        \n",
    "        trace_on = False\n",
    "        if idx == 0 and i == 0:\n",
    "            trace_on = True\n",
    "        \n",
    "        counter += 1\n",
    "        \n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        \n",
    "        model.zero_grad()\n",
    "        \n",
    "        h = tuple([e.data for e in h])\n",
    "        output, h = model(inputs, h, trace_on=trace_on)\n",
    "        \n",
    "        loss = criterion(output.squeeze(), labels.float())\n",
    "        loss.backward()\n",
    "        \n",
    "        nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
    "        \n",
    "        optimizer.step()\n",
    "        \n",
    "        if counter % print_every == 0:\n",
    "            \n",
    "            val_h = model.init_hidden(batch_size, trace_on=False)\n",
    "            val_losses = []\n",
    "            model.eval()\n",
    "            \n",
    "            for inp, lab in val_loader:\n",
    "                val_h = tuple([each.data for each in val_h])\n",
    "                inp, lab = inp.to(device), lab.to(device)\n",
    "                out, val_h = model(inp, val_h, trace_on=False)\n",
    "                val_loss = criterion(out.squeeze(), lab.float())\n",
    "                val_losses.append(val_loss.item())\n",
    "                \n",
    "            model.train()\n",
    "            \n",
    "            print(\"Epoch: {}/{}...\".format(i+1, epochs),\n",
    "                  \"Step: {}...\".format(counter),\n",
    "                  \"Loss: {:.6f}...\".format(loss.item()),\n",
    "                  \"Val Loss: {:.6f}\".format(np.mean(val_losses)))\n",
    "            \n",
    "            if np.mean(val_losses) <= valid_loss_min:\n",
    "                torch.save(model.state_dict(), './state_dict.pt')\n",
    "                print('Validation loss decreased ({:.6f} --> {:.6f}).  Saving model ...'.format(valid_loss_min, np.mean(val_losses)))\n",
    "                valid_loss_min = np.mean(val_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Loading the best model\n",
    "model.load_state_dict(torch.load('./state_dict.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.179\n",
      "Test accuracy: 93.075%\n"
     ]
    }
   ],
   "source": [
    "# Check test set performance.\n",
    "\n",
    "test_losses = []\n",
    "num_correct = 0\n",
    "h = model.init_hidden(batch_size, trace_on=False)\n",
    "\n",
    "model.eval()\n",
    "for inputs, labels in test_loader:\n",
    "    h = tuple([each.data for each in h])\n",
    "    inputs, labels = inputs.to(device), labels.to(device)\n",
    "    output, h = model(inputs, h)\n",
    "    test_loss = criterion(output.squeeze(), labels.float())\n",
    "    test_losses.append(test_loss.item())\n",
    "    pred = torch.round(output.squeeze()) #rounds the output to 0/1\n",
    "    correct_tensor = pred.eq(labels.float().view_as(pred))\n",
    "    correct = np.squeeze(correct_tensor.cpu().numpy())\n",
    "    num_correct += np.sum(correct)\n",
    "        \n",
    "print(\"Test loss: {:.3f}\".format(np.mean(test_losses)))\n",
    "test_acc = num_correct/len(test_loader.dataset)\n",
    "print(\"Test accuracy: {:.3f}%\".format(test_acc*100))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:py37_pytorch_tutorials_gabrielloye] *",
   "language": "python",
   "name": "conda-env-py37_pytorch_tutorials_gabrielloye-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
